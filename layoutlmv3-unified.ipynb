{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b791ba-5675-4eca-9adc-e91e3ef2abcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c12ecb44-ad08-4bd1-abe7-1dae0acf05e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 27 17:21:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:00:06.0 Off |                  N/A |\n",
      "| 27%   39C    P8    20W / 250W |   1714MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:00:0A.0 Off |                  N/A |\n",
      "| 59%   61C    P2   144W / 250W |   9574MiB / 11019MiB |     35%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     32178      C   ...nnh8/torch_env/bin/python     1711MiB |\n",
      "|    1   N/A  N/A      3283      C   ...tx2/env_ocr/bin/python3.7     9571MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512559bc-07f2-424d-a77b-437cb4c49779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/data/tungtx2/tmp/transformers_hub'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e10e97-9052-42f2-923e-d990d726e392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac1f19-1c52-481f-8bc6-b33a277d4189",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92cf037-24f8-4aeb-bc14-be50f3bb0aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 112681\n",
      "account_number : 1326\n",
      "marker_account_number : 1878\n",
      "swift_code : 803\n",
      "marker_swift_code : 1514\n",
      "bank_name : 4822\n",
      "marker_bank_name : 1559\n",
      "fax : 1411\n",
      "marker_fax : 1171\n",
      "phone : 1885\n",
      "marker_phone : 1388\n",
      "company_address : 11759\n",
      "company_name : 8257\n",
      "marker_company_name : 2962\n",
      "bank_address : 4191\n",
      "marker_bank_address : 542\n",
      "marker_company_address : 1013\n",
      "represented_position : 1351\n",
      "marker_represented_position : 335\n",
      "represented_name : 2549\n",
      "marker_represented_name : 1455\n",
      "tax : 695\n",
      "marker_tax : 1024\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'unified_data/train'\n",
    "val_dir = 'unified_data/val'\n",
    "\n",
    "def find_all_labels(data_dir, disable_marker=False):\n",
    "    labels = {}\n",
    "    for jp in Path(data_dir).rglob('*.json'):\n",
    "        data = json.load(open(jp))\n",
    "        for shape in data['shapes']:\n",
    "            if disable_marker and 'marker' in shape['label']:\n",
    "                label = 'text'\n",
    "            else:\n",
    "                label = shape['label']\n",
    "                \n",
    "            if label in labels:\n",
    "                labels[label] += 1\n",
    "            else:\n",
    "                labels[label] = 1\n",
    "                \n",
    "    return labels\n",
    "\n",
    "train_labels = find_all_labels(train_dir, disable_marker=False)\n",
    "val_labels = find_all_labels(val_dir, disable_marker=False)\n",
    "assert set(train_labels.keys()) == set(val_labels.keys())\n",
    "for k, v in train_labels.items():\n",
    "    print(k, ':', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ae76e4-d587-4a5a-970e-cd7c5803b103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company_address': 0, 'account_number': 1, 'marker_fax': 2, 'represented_position': 3, 'marker_bank_address': 4, 'phone': 5, 'bank_name': 6, 'marker_account_number': 7, 'marker_represented_position': 8, 'fax': 9, 'swift_code': 10, 'represented_name': 11, 'tax': 12, 'text': 13, 'marker_swift_code': 14, 'marker_tax': 15, 'marker_company_address': 16, 'marker_company_name': 17, 'marker_bank_name': 18, 'marker_represented_name': 19, 'bank_address': 20, 'company_name': 21, 'marker_phone': 22}\n",
      "{0: 'company_address', 1: 'account_number', 2: 'marker_fax', 3: 'represented_position', 4: 'marker_bank_address', 5: 'phone', 6: 'bank_name', 7: 'marker_account_number', 8: 'marker_represented_position', 9: 'fax', 10: 'swift_code', 11: 'represented_name', 12: 'tax', 13: 'text', 14: 'marker_swift_code', 15: 'marker_tax', 16: 'marker_company_address', 17: 'marker_company_name', 18: 'marker_bank_name', 19: 'marker_represented_name', 20: 'bank_address', 21: 'company_name', 22: 'marker_phone'}\n"
     ]
    }
   ],
   "source": [
    "label_list = list(set(train_labels.keys()))\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id2label = {idx: label for idx, label in enumerate(label_list)}\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b923c75-24fa-4f0d-aa0c-22ccfff6016f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model and Procesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6abc5a6-379c-4bce-9fe5-8c8ed2fdff28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutLMv3ForTokenClassification(\n",
      "  (layoutlmv3): LayoutLMv3Model(\n",
      "    (embeddings): LayoutLMv3TextEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (x_position_embeddings): Embedding(1024, 128)\n",
      "      (y_position_embeddings): Embedding(1024, 128)\n",
      "      (h_position_embeddings): Embedding(1024, 128)\n",
      "      (w_position_embeddings): Embedding(1024, 128)\n",
      "    )\n",
      "    (patch_embed): LayoutLMv3PatchEmbeddings(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (encoder): LayoutLMv3Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_pos_bias): Linear(in_features=32, out_features=12, bias=False)\n",
      "      (rel_pos_x_bias): Linear(in_features=64, out_features=12, bias=False)\n",
      "      (rel_pos_y_bias): Linear(in_features=64, out_features=12, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): LayoutLMv3ClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=23, bias=True)\n",
      "  )\n",
      ")\n",
      "LayoutLMv3Processor:\n",
      "- image_processor: LayoutLMv3ImageProcessor {\n",
      "  \"apply_ocr\": false,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"feature_extractor_type\": \"LayoutLMv3FeatureExtractor\",\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_processor_type\": \"LayoutLMv3ImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"ocr_lang\": null,\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"tesseract_config\": \"\"\n",
      "}\n",
      "\n",
      "- tokenizer: LayoutLMv3TokenizerFast(name_or_path='ckpt/unified/layoutlmv3_unified/checkpoint-4400', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)})\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3ForTokenClassification, LayoutLMv3Processor, AdamW\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model_path = 'ckpt/unified/layoutlmv3_unified/checkpoint-4400'\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(model_path)\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "\n",
    "processor = LayoutLMv3Processor.from_pretrained(model_path, apply_ocr=False)\n",
    "processor.tokenizer.only_label_first_subword = False\n",
    "\n",
    "\n",
    "print(model)\n",
    "print(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3dbb0-47df-4b59-b8a3-45a538594806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model.classifier.out_proj = nn.Linear(in_features=768, out_features=len(label_list), bias=True)\n",
    "\n",
    "model.num_labels = len(label_list)\n",
    "\n",
    "print(model)\n",
    "print()\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a68f235-f682-43ad-a268-124b1cba628e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d4baace-baa1-435c-9a65-e915f144a5e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import unidecode\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pdb\n",
    "import xml.etree.ElementTree as ET\n",
    "from shapely.geometry import Polygon\n",
    "import cv2\n",
    "\n",
    "\n",
    "def normalize_bbox(bbox, width, height):\n",
    "     return [\n",
    "         int(1000 * (bbox[0] / width)),\n",
    "         int(1000 * (bbox[1] / height)),\n",
    "         int(1000 * (bbox[2] / width)),\n",
    "         int(1000 * (bbox[3] / height)),\n",
    "     ]\n",
    "    \n",
    "    \n",
    "def parse_xml(xml_path):\n",
    "    root = ET.parse(xml_path).getroot()\n",
    "    objs = root.findall('object')\n",
    "    boxes, obj_names = [], []\n",
    "    for obj in objs:\n",
    "        obj_name = obj.find('name').text\n",
    "        box = obj.find('bndbox')\n",
    "        xmin = int(box.find('xmin').text)\n",
    "        ymin = int(box.find('ymin').text)\n",
    "        xmax = int(box.find('xmax').text)\n",
    "        ymax = int(box.find('ymax').text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        obj_names.append(obj_name)\n",
    "    return boxes, obj_names\n",
    "\n",
    "\n",
    "def widen_box(box, percent_x, percent_y):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        xmin -= w * percent_x\n",
    "        ymin -= h * percent_y\n",
    "        xmax += w * percent_x\n",
    "        ymax += h * percent_y\n",
    "        return (int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "\n",
    "    \n",
    "def draw_json_on_img(img, json_data):\n",
    "    labels = list(set(shape['label'] for shape in json_data['shapes']))\n",
    "    color = {}\n",
    "    for i in range(len(labels)):\n",
    "        color[labels[i]] = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
    "        \n",
    "    img = img.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_size = 0.5# Draw the text on the image\n",
    "    # font = ImageFont.truetype(font.font.family, font_size)\n",
    "    for i, shape in enumerate(json_data['shapes']):\n",
    "        polys = shape['points']\n",
    "        polys = [(int(pt[0]), int(pt[1])) for pt in polys]\n",
    "        label = shape['label']\n",
    "        draw.polygon(polys, outline=color[label], width=2)\n",
    "        # Draw the text on the image\n",
    "        img = np.array(img)\n",
    "        cv2.putText(img, shape['label'], (polys[0][0], polys[0][1]-5), font, font_size, color[label], thickness=1)\n",
    "        img = Image.fromarray(img)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "    return img\n",
    "    \n",
    "    \n",
    "def mask_image(img, boxes, json_data, widen_range_x, widen_range_y):\n",
    "    # widen block\n",
    "    if isinstance(widen_range_x, list) and isinstance(widen_range_y, list):\n",
    "        boxes = [widen_box(box, np.random.uniform(widen_range_x[0], widen_range_x[1]), np.random.uniform(widen_range_y[0], widen_range_y[1])) for box in boxes]\n",
    "    else:\n",
    "        boxes = [widen_box(box, widen_range_x, widen_range_y) for box in boxes]\n",
    "    \n",
    "    ls_polys2keep = []\n",
    "    ls_area2keep = []\n",
    "    iou_threshold = 0.\n",
    "    for box_idx, box in enumerate(boxes):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        box_pts = [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]\n",
    "        p_box = Polygon(box_pts)\n",
    "        for shape_idx, shape in enumerate(json_data['shapes']):\n",
    "            if shape_idx in ls_polys2keep:\n",
    "                continue\n",
    "            pts = shape['points']\n",
    "            p_shape = Polygon(pts)\n",
    "            intersect_area = p_box.intersection(p_shape).area\n",
    "            if intersect_area / p_shape.area > iou_threshold:\n",
    "                ls_polys2keep.append(shape_idx)\n",
    "                pts = [coord for pt in pts for coord in pt]\n",
    "                poly_xmin = min(pts[::2])\n",
    "                poly_ymin = min(pts[1::2])\n",
    "                poly_xmax = max(pts[::2])\n",
    "                poly_ymax = max(pts[1::2])\n",
    "                ls_area2keep.append((poly_xmin, poly_ymin, poly_xmax, poly_ymax))\n",
    "\n",
    "    # mask white all area of image that is not in block\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        xmin = max(0, xmin)\n",
    "        ymin = max(0, ymin)\n",
    "        xmax = min(img.shape[1], xmax)\n",
    "        ymax = min(img.shape[0], ymax)\n",
    "        mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "    for area2keep in ls_area2keep:\n",
    "        xmin, ymin, xmax, ymax = area2keep\n",
    "        xmin = int(max(0, xmin))\n",
    "        ymin = int(max(0, ymin))\n",
    "        xmax = int(min(img.shape[1], xmax))\n",
    "        ymax = int(min(img.shape[0], ymax))\n",
    "        mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "    # mask white\n",
    "    img[mask == 0] = 255\n",
    "\n",
    "    # delete all poly that is not in block\n",
    "    ls_idx2del = [idx for idx, shape in enumerate(json_data['shapes']) if idx not in ls_polys2keep]\n",
    "    for idx in sorted(ls_idx2del, reverse=True):\n",
    "        del json_data['shapes'][idx]\n",
    "\n",
    "    return img, json_data\n",
    "        \n",
    "def get_random_area_not_in_block(img_w, img_h, block_boxes):\n",
    "    ls_block_w = [box[2]-box[0] for box in block_boxes]\n",
    "    ls_block_h = [box[3]-box[1] for box in block_boxes]\n",
    "    min_w, max_w = min(ls_block_w), max(ls_block_w)\n",
    "    min_h, max_h = min(ls_block_h), max(ls_block_h)\n",
    "    w = np.random.randint(min_w, max_w)\n",
    "    h = np.random.randint(min_h, max_h)\n",
    "    \n",
    "    mask = np.zeros((img_h, img_w))\n",
    "    for xmin, ymin, xmax, ymax in block_boxes:\n",
    "        mask[ymin:ymax, xmin:xmax] = 1\n",
    "    for _ in range(10):\n",
    "        xmin = np.random.randint(0, img_w-w)\n",
    "        ymin = np.random.randint(0, img_h-h)\n",
    "        if np.any(mask[ymin:ymin+h, xmin:xmin+w]==1):\n",
    "            continue\n",
    "        else:\n",
    "            return (xmin, ymin, xmin+w, ymin+h)\n",
    "    \n",
    "    return None\n",
    "    \n",
    "def gen_annotation_for_img(img_fp, xml_fp, json_fp, mask_type='unified', widen_range_x=[0.1, 0.2], widen_range_y=[0.1, 0.25], disable_marker=False, remove_accent=True, augment=False):\n",
    "    img = Image.open(img_fp).convert(\"RGB\")\n",
    "    json_data = json.load(open(json_fp))\n",
    "    \n",
    "    is_masked = False\n",
    "    if mask_type == 'masked' or (mask_type=='unified' and np.random.rand() < 0.5):\n",
    "        block_boxes, obj_names = parse_xml(xml_fp)  # get detected blocks\n",
    "        \n",
    "        if np.random.rand() < 0.3:   # them ngau nhien 1 block bat nham\n",
    "            try:\n",
    "                new_block = get_random_area_not_in_block(img.size[0], img.size[1], block_boxes)\n",
    "                if new_block is not None:\n",
    "                    if np.random.rand() < 0.8:\n",
    "                        block_boxes.append(new_block)\n",
    "                    else:\n",
    "                        del block_boxes[np.random.randint(0, len(block_boxes))]\n",
    "                        block_boxes.append(new_block)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        img, json_data = mask_image(np.array(img), boxes=block_boxes, json_data=json_data, widen_range_x=widen_range_x, widen_range_y=widen_range_y)\n",
    "        img = Image.fromarray(img)\n",
    "        is_masked = True\n",
    "    \n",
    "    if augment and np.random.rand() < 0.3:  # random drop some boxes\n",
    "        size = int(0.08*len(json_data['shapes'])) if not is_masked else int(0.05*len(json_data['shapes']))\n",
    "        idx2drop = np.random.choice(list(range(len(json_data['shapes']))), size=size)\n",
    "        json_data['shapes'] = [shape for i, shape in enumerate(json_data['shapes']) if i not in idx2drop]\n",
    "            \n",
    "    # pdb.set_trace()\n",
    "        \n",
    "    words, orig_polys, normalized_boxes, labels = [], [], [], []\n",
    "    img_h, img_w = json_data['imageHeight'], json_data['imageWidth']\n",
    "    for i, shape in enumerate(json_data['shapes']):\n",
    "        if disable_marker and 'marker' in shape['label']:\n",
    "            current_label = 'text'\n",
    "        else:\n",
    "            current_label = shape['label']\n",
    "        \n",
    "        if remove_accent:\n",
    "            words.append(unidecode.unidecode(shape['text'].lower()))\n",
    "        else:\n",
    "            words.append(shape['text'].lower())\n",
    "            \n",
    "        labels.append(current_label)\n",
    "        pts = [coord for pt in shape['points'] for coord in pt]\n",
    "        xmin = min(pts[0::2])\n",
    "        xmax = max(pts[0::2])\n",
    "        ymin = min(pts[1::2])\n",
    "        ymax = max(pts[1::2])\n",
    "\n",
    "        xmin = max(xmin, 0)\n",
    "        ymin = max(ymin, 0)\n",
    "        xmax = min(img_w, xmax)\n",
    "        ymax = min(img_h, ymax)\n",
    "\n",
    "        normalized_boxes.append(normalize_bbox((xmin, ymin, xmax, ymax), img_w, img_h))\n",
    "        orig_polys.append(tuple([tuple(pt) for pt in shape['points']]))\n",
    "        \n",
    "    return img, words, orig_polys, normalized_boxes, labels\n",
    "\n",
    "\n",
    "class CORDDataset(Dataset):\n",
    "    \"\"\"CORD dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 file_paths, \n",
    "                 processor=None, \n",
    "                 max_length=512, \n",
    "                 mask_type='unified', \n",
    "                 widen_range_x=[0.1, 0.2], \n",
    "                 widen_range_y=[0.1, 0.25], \n",
    "                 disable_marker=False, \n",
    "                 augment=False,\n",
    "                 remove_accent = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotations (List[List]): List of lists containing the word-level annotations (words, labels, boxes).\n",
    "            image_dir (string): Directory with all the document images.\n",
    "            processor (LayoutLMv2Processor): Processor to prepare the text + image.\n",
    "        \"\"\"\n",
    "        self.ls_img_fp, self.ls_xml_fp, self.ls_json_fp = file_paths\n",
    "        assert len(self.ls_img_fp) == len(self.ls_json_fp) == len(self.ls_xml_fp)\n",
    "        self.processor = processor\n",
    "        self.mask_type = mask_type\n",
    "        self.widen_range_x = widen_range_x\n",
    "        self.widen_range_y = widen_range_y\n",
    "        self.disable_marker = disable_marker\n",
    "        self.augment = augment\n",
    "        self.remove_accent = remove_accent\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ls_img_fp)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # first, take an image\n",
    "        img_fp = self.ls_img_fp[index]\n",
    "        xml_fp = self.ls_xml_fp[index]\n",
    "        json_fp = self.ls_json_fp[index]\n",
    "        \n",
    "        img, words, _, boxes, text_labels = gen_annotation_for_img(img_fp, xml_fp, json_fp, \n",
    "                                                                   mask_type=self.mask_type, \n",
    "                                                                   widen_range_x=self.widen_range_x, widen_range_y=self.widen_range_y, \n",
    "                                                                   disable_marker=self.disable_marker, \n",
    "                                                                   augment=self.augment,\n",
    "                                                                   remove_accent=self.remove_accent)\n",
    "        idx_labels = [label2id[label] for label in text_labels]\n",
    "\n",
    "        encoded_inputs = self.processor(img, words, boxes=boxes, word_labels=idx_labels, truncation=True, stride =128, \n",
    "                            padding=\"max_length\", max_length=512, return_overflowing_tokens=True, return_offsets_mapping=True, return_tensors=\"pt\")  \n",
    "        \n",
    "        # print(encoded_inputs.keys())\n",
    "        overflow_to_sample_mapping = encoded_inputs.pop('overflow_to_sample_mapping')\n",
    "        offset_mapping = encoded_inputs.pop('offset_mapping')\n",
    "        # print('overflow_to_sample_mapping: ', overflow_to_sample_mapping)\n",
    "        # print('offset_mapping: ', offset_mapping)\n",
    "\n",
    "        # remove batch dimension\n",
    "        idx = np.random.randint(0, len(encoded_inputs['pixel_values']))\n",
    "        for k, v in encoded_inputs.items():\n",
    "            encoded_inputs[k] = v[idx]\n",
    "      \n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9043099-deab-4970-bc3c-346f2879aa34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(data_dir):\n",
    "    ls_img_fp, ls_xml_fp, ls_json_fp = [], [], []\n",
    "    for img_fp in Path(data_dir).rglob('*.jpg'):\n",
    "        json_fp = img_fp.with_suffix('.json')\n",
    "        xml_fp = img_fp.with_suffix('.xml')\n",
    "        \n",
    "        ls_img_fp.append(str(img_fp))\n",
    "        ls_xml_fp.append(str(xml_fp))\n",
    "        ls_json_fp.append(str(json_fp))\n",
    "    \n",
    "    return ls_img_fp, ls_xml_fp, ls_json_fp\n",
    "\n",
    "\n",
    "train_file_paths = get_file_paths(train_dir)\n",
    "val_file_paths = get_file_paths(val_dir)\n",
    "\n",
    "widen_range_x = [0., 0.01]\n",
    "widen_range_y = [0.15, 0.3]\n",
    "disable_marker = False\n",
    "mask_type = 'unified'\n",
    "remove_accent = True\n",
    "\n",
    "train_dataset = CORDDataset(file_paths=train_file_paths, processor=processor, mask_type=mask_type, \n",
    "                            widen_range_x=widen_range_x, widen_range_y=widen_range_y, disable_marker=disable_marker, \n",
    "                            augment=True, remove_accent=remove_accent)\n",
    "\n",
    "val_dataset = CORDDataset(file_paths=val_file_paths, processor=processor, mask_type=mask_type, \n",
    "                          widen_range_x=0.1, widen_range_y=0.2, disable_marker=disable_marker, \n",
    "                          augment=False, remove_accent=remove_accent)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29ecc7dc-0ae8-4b90-9a53-d52df781a620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unified_data/train/train_labeled_ocred/CTR 973 (1)-001 (1)_0.jpg'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_paths[0][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12c0b49b-27b0-493c-906e-44497b302a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([512])\n",
      "attention_mask torch.Size([512])\n",
      "bbox torch.Size([512, 4])\n",
      "labels torch.Size([512])\n",
      "pixel_values torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# drawed = draw_json_on_img(img, json_data)\n",
    "# drawed.save('a.jpg')\n",
    "encoding = train_dataset[8]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5a2674c-35b9-43f2-8749-f3d789e4194f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.remove_accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a6c7314-9dff-4fa9-9b8a-bd33ac09e081",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "(' 384', 'account_number', tensor([235, 845, 354, 861]))\n",
      "('37', 'account_number', tensor([235, 845, 354, 861]))\n",
      "('66', 'account_number', tensor([235, 845, 354, 861]))\n",
      "('70', 'account_number', tensor([235, 845, 354, 861]))\n",
      "('62', 'account_number', tensor([235, 845, 354, 861]))\n",
      "('80', 'account_number', tensor([235, 845, 354, 861]))\n",
      "('91', 'account_number', tensor([235, 845, 354, 861]))\n",
      "('01', 'account_number', tensor([235, 845, 354, 861]))\n",
      "(' no', 'marker_account_number', tensor([207, 844, 232, 860]))\n",
      "(':', 'marker_account_number', tensor([207, 844, 232, 860]))\n",
      "(' ar', 'marker_account_number', tensor([183, 846, 204, 856]))\n",
      "(' beneficiary', 'marker_account_number', tensor([ 99, 844, 180, 856]))\n",
      "(' l', 'company_name', tensor([505, 836, 535, 848]))\n",
      "('td', 'company_name', tensor([505, 836, 535, 848]))\n",
      "(' co', 'company_name', tensor([478, 835, 503, 850]))\n",
      "(' glass', 'company_name', tensor([433, 835, 479, 850]))\n",
      "(' pharmaceutical', 'company_name', tensor([317, 836, 430, 847]))\n",
      "(' sh', 'company_name', tensor([238, 834, 313, 847]))\n",
      "('and', 'company_name', tensor([238, 834, 313, 847]))\n",
      "('ong', 'company_name', tensor([238, 834, 313, 847]))\n",
      "(' name', 'marker_company_name', tensor([194, 833, 232, 847]))\n",
      "(' beneficiary', 'marker_company_name', tensor([101, 833, 190, 845]))\n",
      "(\"'s\", 'marker_company_name', tensor([101, 833, 190, 845]))\n",
      "(' 8', 'swift_code', tensor([183, 822, 268, 834]))\n",
      "('k', 'swift_code', tensor([183, 822, 268, 834]))\n",
      "('ch', 'swift_code', tensor([183, 822, 268, 834]))\n",
      "('cn', 'swift_code', tensor([183, 822, 268, 834]))\n",
      "('bj', 'swift_code', tensor([183, 822, 268, 834]))\n",
      "('50', 'swift_code', tensor([183, 822, 268, 834]))\n",
      "(' code', 'marker_swift_code', tensor([142, 821, 177, 833]))\n",
      "(' swift', 'marker_swift_code', tensor([ 99, 820, 138, 833]))\n",
      "(' ch', 'bank_address', tensor([437, 810, 482, 824]))\n",
      "('ina', 'bank_address', tensor([437, 810, 482, 824]))\n",
      "(' sh', 'bank_address', tensor([360, 810, 434, 823]))\n",
      "('and', 'bank_address', tensor([360, 810, 434, 823]))\n",
      "('ong', 'bank_address', tensor([360, 810, 434, 823]))\n",
      "(' z', 'bank_address', tensor([326, 809, 358, 823]))\n",
      "('ibo', 'bank_address', tensor([326, 809, 358, 823]))\n",
      "(' y', 'bank_address', tensor([275, 808, 326, 824]))\n",
      "('iy', 'bank_address', tensor([275, 808, 326, 824]))\n",
      "('uan', 'bank_address', tensor([275, 808, 326, 824]))\n",
      "(' z', 'bank_address', tensor([185, 809, 251, 822]))\n",
      "('hen', 'bank_address', tensor([185, 809, 251, 822]))\n",
      "('x', 'bank_address', tensor([185, 809, 251, 822]))\n",
      "('ing', 'bank_address', tensor([185, 809, 251, 822]))\n",
      "(' r', 'bank_address', tensor([252, 808, 276, 823]))\n",
      "('d', 'bank_address', tensor([252, 808, 276, 823]))\n",
      "(' add', 'marker_bank_address', tensor([135, 807, 165, 822]))\n",
      "(':', 'marker_bank_address', tensor([135, 807, 165, 822]))\n",
      "(' bank', 'marker_bank_address', tensor([ 99, 807, 135, 821]))\n",
      "(' sub', 'bank_name', tensor([421, 798, 504, 813]))\n",
      "('-', 'bank_name', tensor([421, 798, 504, 813]))\n",
      "('br', 'bank_name', tensor([421, 798, 504, 813]))\n",
      "('anch', 'bank_name', tensor([421, 798, 504, 813]))\n",
      "(' y', 'bank_name', tensor([371, 798, 418, 812]))\n",
      "('iy', 'bank_name', tensor([371, 798, 418, 812]))\n",
      "('uan', 'bank_name', tensor([371, 798, 418, 812]))\n",
      "(' branch', 'bank_name', tensor([312, 796, 368, 810]))\n",
      "(' z', 'bank_name', tensor([279, 796, 312, 810]))\n",
      "('ib', 'bank_name', tensor([279, 796, 312, 810]))\n",
      "('c', 'bank_name', tensor([279, 796, 312, 810]))\n",
      "(' ch', 'bank_name', tensor([235, 796, 279, 810]))\n",
      "('ina', 'bank_name', tensor([235, 796, 279, 810]))\n",
      "(' :', 'bank_name', tensor([211, 795, 235, 810]))\n",
      "('of', 'bank_name', tensor([211, 795, 235, 810]))\n",
      "(' bank', 'bank_name', tensor([177, 795, 213, 809]))\n",
      "(' name', 'marker_bank_name', tensor([137, 795, 174, 809]))\n",
      "(' bank', 'marker_bank_name', tensor([ 99, 794, 134, 808]))\n",
      "(' details', 'text', tensor([137, 783, 191, 796]))\n",
      "(' h', 'text', tensor([ 98, 782, 135, 795]))\n",
      "('ank', 'text', tensor([ 98, 782, 135, 795]))\n",
      "(' goods', 'text', tensor([418, 767, 468, 781]))\n",
      "(' receipt', 'text', tensor([333, 768, 386, 778]))\n",
      "(' the', 'text', tensor([388, 766, 418, 781]))\n",
      "(' er', 'text', tensor([309, 764, 332, 780]))\n",
      "(' af', 'text', tensor([285, 764, 309, 780]))\n",
      "(' 00', 'text', tensor([255, 764, 285, 780]))\n",
      "('8', 'text', tensor([255, 764, 285, 780]))\n",
      "(' terms', 'text', tensor([178, 764, 226, 778]))\n",
      "(':', 'text', tensor([178, 764, 226, 778]))\n",
      "(' t', 'text', tensor([229, 763, 254, 780]))\n",
      "('t', 'text', tensor([229, 763, 254, 780]))\n",
      "(' payment', 'text', tensor([113, 763, 172, 776]))\n",
      "(' 9', 'text', tensor([ 98, 762, 110, 778]))\n",
      "('.', 'text', tensor([ 98, 762, 110, 778]))\n",
      "(' seller', 'text', tensor([350, 752, 401, 766]))\n",
      "(' the', 'text', tensor([321, 750, 349, 766]))\n",
      "(' ey', 'text', tensor([299, 750, 323, 766]))\n",
      "(' covered', 'text', tensor([235, 750, 301, 763]))\n",
      "(' insurance', 'text', tensor([113, 749, 188, 762]))\n",
      "(' be', 'text', tensor([213, 748, 233, 764]))\n",
      "(' ro', 'text', tensor([191, 748, 215, 764]))\n",
      "(' 8', 'text', tensor([ 98, 748, 110, 763]))\n",
      "('.', 'text', tensor([ 98, 748, 110, 763]))\n",
      "(' seller', 'text', tensor([514, 192, 569, 209]))\n",
      "(':', 'text', tensor([514, 192, 569, 209]))\n",
      "(' the', 'text', tensor([487, 192, 513, 207]))\n",
      "(' an', 'text', tensor([283, 188, 315, 205]))\n",
      "('i', 'text', tensor([283, 188, 315, 205]))\n",
      "(':', 'text', tensor([283, 188, 315, 205]))\n",
      "(' contract', 'text', tensor([137, 188, 207, 203]))\n",
      "(' rs', 'text', tensor([207, 188, 222, 203]))\n",
      "(' this', 'text', tensor([104, 187, 135, 202]))\n",
      "(' chat', 'represented_name', tensor([729, 155, 768, 169]))\n",
      "(' t', 'represented_name', tensor([699, 155, 729, 169]))\n",
      "('ien', 'represented_name', tensor([699, 155, 729, 169]))\n",
      "(' n', 'represented_name', tensor([640, 155, 696, 168]))\n",
      "('guyen', 'represented_name', tensor([640, 155, 696, 168]))\n",
      "(' m', 'represented_name', tensor([613, 154, 638, 168]))\n",
      "('r', 'represented_name', tensor([613, 154, 638, 168]))\n",
      "('.', 'represented_name', tensor([613, 154, 638, 168]))\n",
      "(' av', 'marker_represented_name', tensor([580, 153, 609, 167]))\n",
      "('.', 'marker_represented_name', tensor([580, 153, 609, 167]))\n",
      "(' representative', 'marker_represented_name', tensor([466, 151, 580, 166]))\n",
      "(' +', 'fax', tensor([136, 147, 227, 162]))\n",
      "('85', 'fax', tensor([136, 147, 227, 162]))\n",
      "('-', 'fax', tensor([136, 147, 227, 162]))\n",
      "('533', 'fax', tensor([136, 147, 227, 162]))\n",
      "('-', 'fax', tensor([136, 147, 227, 162]))\n",
      "('32', 'fax', tensor([136, 147, 227, 162]))\n",
      "('30', 'fax', tensor([136, 147, 227, 162]))\n",
      "('78', 'fax', tensor([136, 147, 227, 162]))\n",
      "(' fax', 'marker_fax', tensor([103, 146, 136, 163]))\n",
      "(':', 'marker_fax', tensor([103, 146, 136, 163]))\n",
      "(' /', 'phone', tensor([732, 146, 788, 155]))\n",
      "('365', 'phone', tensor([732, 146, 788, 155]))\n",
      "('17', 'phone', tensor([732, 146, 788, 155]))\n",
      "('45', 'phone', tensor([732, 146, 788, 155]))\n",
      "(' 4', 'phone', tensor([660, 143, 726, 156]))\n",
      "('.', 'phone', tensor([660, 143, 726, 156]))\n",
      "('38', 'phone', tensor([660, 143, 726, 156]))\n",
      "('69', 'phone', tensor([660, 143, 726, 156]))\n",
      "('255', 'phone', tensor([660, 143, 726, 156]))\n",
      "(' +', 'phone', tensor([638, 142, 665, 156]))\n",
      "('84', 'phone', tensor([638, 142, 665, 156]))\n",
      "(' number', 'marker_phone', tensor([576, 143, 631, 155]))\n",
      "(' telephone', 'marker_phone', tensor([469, 141, 569, 153]))\n",
      "('/', 'marker_phone', tensor([469, 141, 569, 153]))\n",
      "('fax', 'marker_phone', tensor([469, 141, 569, 153]))\n",
      "(' +', 'phone', tensor([136, 135, 226, 150]))\n",
      "('86', 'phone', tensor([136, 135, 226, 150]))\n",
      "('-', 'phone', tensor([136, 135, 226, 150]))\n",
      "('533', 'phone', tensor([136, 135, 226, 150]))\n",
      "('-', 'phone', tensor([136, 135, 226, 150]))\n",
      "('3', 'phone', tensor([136, 135, 226, 150]))\n",
      "('259', 'phone', tensor([136, 135, 226, 150]))\n",
      "('16', 'phone', tensor([136, 135, 226, 150]))\n",
      "(' tel', 'marker_phone', tensor([105, 134, 135, 149]))\n",
      "(':', 'marker_phone', tensor([105, 134, 135, 149]))\n",
      "(' v', 'company_address', tensor([688, 133, 743, 144]))\n",
      "('iet', 'company_address', tensor([688, 133, 743, 144]))\n",
      "('nam', 'company_address', tensor([688, 133, 743, 144]))\n",
      "(' city', 'company_address', tensor([651, 132, 685, 144]))\n",
      "(',', 'company_address', tensor([651, 132, 685, 144]))\n",
      "(' h', 'company_address', tensor([609, 133, 649, 142]))\n",
      "('ano', 'company_address', tensor([609, 133, 649, 142]))\n",
      "('i', 'company_address', tensor([609, 133, 649, 142]))\n",
      "(' district', 'company_address', tensor([541, 129, 604, 144]))\n",
      "(' ho', 'company_address', tensor([467, 129, 514, 142]))\n",
      "('ang', 'company_address', tensor([467, 129, 514, 142]))\n",
      "(' m', 'company_address', tensor([516, 128, 541, 143]))\n",
      "('ai', 'company_address', tensor([516, 128, 541, 143]))\n",
      "(' ch', 'company_address', tensor([280, 125, 324, 141]))\n",
      "('ina', 'company_address', tensor([280, 125, 324, 141]))\n",
      "(' p', 'company_address', tensor([249, 124, 281, 141]))\n",
      "('.', 'company_address', tensor([249, 124, 281, 141]))\n",
      "('r', 'company_address', tensor([249, 124, 281, 141]))\n",
      "('.', 'company_address', tensor([249, 124, 281, 141]))\n",
      "(' province', 'company_address', tensor([180, 124, 249, 138]))\n",
      "(' sh', 'company_address', tensor([107, 123, 177, 136]))\n",
      "('and', 'company_address', tensor([107, 123, 177, 136]))\n",
      "('ong', 'company_address', tensor([107, 123, 177, 136]))\n",
      "(' ward', 'company_address', tensor([683, 120, 729, 133]))\n",
      "('.', 'company_address', tensor([683, 120, 729, 133]))\n",
      "(' m', 'company_address', tensor([657, 118, 683, 133]))\n",
      "('ai', 'company_address', tensor([657, 118, 683, 133]))\n",
      "(' tan', 'company_address', tensor([625, 117, 658, 133]))\n",
      "(' m', 'company_address', tensor([596, 118, 624, 132]))\n",
      "('ai', 'company_address', tensor([596, 118, 624, 132]))\n",
      "(' tan', 'company_address', tensor([568, 116, 598, 132]))\n",
      "(' d', 'company_address', tensor([547, 116, 568, 132]))\n",
      "('5', 'company_address', tensor([547, 116, 568, 132]))\n",
      "(' add', 'marker_company_address', tensor([467, 115, 500, 129]))\n",
      "(':', 'marker_company_address', tensor([467, 115, 500, 129]))\n",
      "(' city', 'company_address', tensor([401, 115, 434, 129]))\n",
      "('.', 'company_address', tensor([401, 115, 434, 129]))\n",
      "(' z', 'company_address', tensor([365, 113, 400, 130]))\n",
      "('iso', 'company_address', tensor([365, 113, 400, 130]))\n",
      "(' county', 'company_address', tensor([307, 114, 363, 128]))\n",
      "(' y', 'company_address', tensor([255, 113, 306, 127]))\n",
      "('iy', 'company_address', tensor([255, 113, 306, 127]))\n",
      "('uan', 'company_address', tensor([255, 113, 306, 127]))\n",
      "(' road', 'company_address', tensor([211, 113, 255, 127]))\n",
      "('.', 'company_address', tensor([211, 113, 255, 127]))\n",
      "(' bu', 'company_address', tensor([172, 112, 211, 127]))\n",
      "('xia', 'company_address', tensor([172, 112, 211, 127]))\n",
      "(' address', 'marker_company_address', tensor([107, 110, 167, 124]))\n",
      "(' limited', 'company_name', tensor([646, 107, 699, 121]))\n",
      "(' company', 'company_name', tensor([580, 107, 646, 120]))\n",
      "(' v', 'company_name', tensor([522, 104, 579, 120]))\n",
      "('iet', 'company_name', tensor([522, 104, 579, 120]))\n",
      "('nam', 'company_name', tensor([522, 104, 579, 120]))\n",
      "(' av', 'company_name', tensor([482, 103, 521, 119]))\n",
      "('on', 'company_name', tensor([482, 103, 521, 119]))\n",
      "(' l', 'company_name', tensor([379, 103, 408, 116]))\n",
      "('td', 'company_name', tensor([379, 103, 408, 116]))\n",
      "('.', 'company_name', tensor([379, 103, 408, 116]))\n",
      "(' co', 'company_name', tensor([350, 101, 380, 118]))\n",
      "('.,', 'company_name', tensor([350, 101, 380, 118]))\n",
      "(' glass', 'company_name', tensor([302, 102, 349, 115]))\n",
      "(' pharmaceutical', 'company_name', tensor([182,  99, 302, 115]))\n",
      "(' and', 'company_name', tensor([124,  98, 179, 113]))\n",
      "('ong', 'company_name', tensor([124,  98, 179, 113]))\n",
      "(' buyer', 'marker_company_name', tensor([498,  90, 546, 103]))\n",
      "(':', 'marker_company_name', tensor([498,  90, 546, 103]))\n",
      "(' the', 'marker_company_name', tensor([468,  89, 495, 103]))\n",
      "(' seller', 'marker_company_name', tensor([136,  83, 189,  99]))\n",
      "(':', 'marker_company_name', tensor([136,  83, 189,  99]))\n",
      "(' the', 'marker_company_name', tensor([107,  82, 134,  96]))\n",
      "(' 2022', 'text', tensor([796,  73, 826,  88]))\n",
      "(' 24', 'text', tensor([777,  73, 795,  86]))\n",
      "(' fe', 'text', tensor([748,  72, 777,  86]))\n",
      "('b', 'text', tensor([748,  72, 777,  86]))\n",
      "(' date', 'text', tensor([680,  70, 721,  84]))\n",
      "(':', 'text', tensor([680,  70, 721,  84]))\n",
      "(' contract', 'text', tensor([608,  70, 676,  82]))\n",
      "(' fl', 'text', tensor([208,  63, 291,  75]))\n",
      "('a', 'text', tensor([208,  63, 291,  75]))\n",
      "('20', 'text', tensor([208,  63, 291,  75]))\n",
      "('220', 'text', tensor([208,  63, 291,  75]))\n",
      "('224', 'text', tensor([208,  63, 291,  75]))\n",
      "(' no', 'text', tensor([175,  62, 207,  75]))\n",
      "('.:', 'text', tensor([175,  62, 207,  75]))\n",
      "(' contract', 'text', tensor([106,  61, 181,  76]))\n",
      "('</s>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "ls_token = [processor.tokenizer.decode(input_id) for input_id in encoding['input_ids']]\n",
    "ls_label = [id2label[int(label_id)] if label_id != -100 else 'SPECIAL' for label_id in encoding['labels'] ]\n",
    "ls_bb = list(encoding['bbox'])\n",
    "for item in zip(ls_token, ls_label, ls_bb):\n",
    "  print(item)\n",
    "  # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2606efa9-5cfb-419d-afce-b7ea5eb5c247",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([2, 512])\n",
      "attention_mask torch.Size([2, 512])\n",
      "bbox torch.Size([2, 512, 4])\n",
      "labels torch.Size([2, 512])\n",
      "pixel_values torch.Size([2, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "for item in train_dataloader:\n",
    "  for k, v in item.items():\n",
    "    print(k, v.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "603acfe9-04aa-4ce7-9056-25b4e2875d05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c1f3b-677b-4159-9939-c503ba2c3291",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hugging Face Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9481cef0-a46a-4ecc-aefc-79add05c9f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company_address',\n",
       " 'account_number',\n",
       " 'marker_fax',\n",
       " 'represented_position',\n",
       " 'marker_bank_address',\n",
       " 'phone',\n",
       " 'bank_name',\n",
       " 'marker_account_number',\n",
       " 'marker_represented_position',\n",
       " 'fax',\n",
       " 'swift_code',\n",
       " 'represented_name',\n",
       " 'tax',\n",
       " 'text',\n",
       " 'marker_swift_code',\n",
       " 'marker_tax',\n",
       " 'marker_company_address',\n",
       " 'marker_company_name',\n",
       " 'marker_bank_name',\n",
       " 'marker_represented_name',\n",
       " 'bank_address',\n",
       " 'company_name',\n",
       " 'marker_phone']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60fabfcb-027c-4d75-bb8a-38863393dbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "return_entity_level_metrics = False\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0f982d2-4644-4019-ba6e-727287173ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"ckpt/unified/layoutlmv3_unified_retrain\",\n",
    "                                  num_train_epochs=50,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  weight_decay=1e-2,\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  save_strategy='steps',\n",
    "                                  eval_steps=400,\n",
    "                                  save_steps=400,\n",
    "                                  save_total_limit=15,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  warmup_ratio = 0.1,\n",
    "                                  do_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7e31e85-72a2-4bb5-bde7-66bae03658e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "  def get_train_dataloader(self):\n",
    "    return train_dataloader\n",
    "\n",
    "  def get_eval_dataloader(self, eval_dataset = None):\n",
    "    return val_dataloader\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705adda3-0d05-4977-b7dc-5398879f682f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='413' max='16750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  413/16750 03:01 < 2:00:29, 2.26 it/s, Epoch 1.23/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.960499</td>\n",
       "      <td>0.969570</td>\n",
       "      <td>0.965013</td>\n",
       "      <td>0.991740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: text seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company_address seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_company_address seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_company_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: account_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_account_number seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: bank_address seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_bank_address seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: bank_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_bank_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: swift_code seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_swift_code seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: tax seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_tax seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: represented_position seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: represented_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_represented_name seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: phone seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_phone seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: fax seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_fax seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: marker_represented_position seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7796fb4-5195-4c63-81f1-01600d8ed2be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = 'ckpt/nonmasked/unified_data/layoutlmv3_unified_data/'\n",
    "max_f1, max_acc = 0, 0\n",
    "best_f1_model, best_acc_model = None, None\n",
    "for model_fn in os.listdir(model_dir):\n",
    "    if model_fn == 'runs':\n",
    "        continue\n",
    "    model_fp = os.path.join(model_dir, model_fn)\n",
    "    loaded_model = LayoutLMv3ForTokenClassification.from_pretrained(model_fp).to('cuda')\n",
    "    trainer.model = loaded_model\n",
    "    res = trainer.evaluate()\n",
    "    if res['eval_f1'] > max_f1:\n",
    "        best_f1_model = model_fn\n",
    "        max_f1 = res['eval_f1']\n",
    "    if res['eval_accuracy'] > max_acc:\n",
    "        best_acc_model = model_fn\n",
    "        max_acc = res['eval_accuracy']\n",
    "\n",
    "print(f'Best f1 model: {best_f1_model} - {max_f1}')\n",
    "print(f'Best acc model: {best_acc_model} - {max_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "504c897a-9e84-4594-852a-323f3fff680e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed checkpoint-14700\n",
      "removed checkpoint-15900\n",
      "removed checkpoint-15600\n",
      "removed checkpoint-12900\n",
      "removed checkpoint-16200\n",
      "removed checkpoint-13500\n",
      "removed checkpoint-13200\n",
      "removed checkpoint-13800\n",
      "removed checkpoint-15000\n",
      "removed checkpoint-16800\n",
      "removed checkpoint-14100\n",
      "removed checkpoint-15300\n",
      "removed checkpoint-12600\n",
      "removed checkpoint-16500\n"
     ]
    }
   ],
   "source": [
    "# delete model\n",
    "import shutil\n",
    "\n",
    "model_dir = 'ckpt/nonmasked/unified_data/layoutlmv3_unified_data/'\n",
    "for model_fn in os.listdir(model_dir):\n",
    "    if model_fn == 'runs':\n",
    "        continue\n",
    "    model_fp = os.path.join(model_dir, model_fn)\n",
    "    if model_fn not in ['checkpoint-14400']:\n",
    "        shutil.rmtree(model_fp)\n",
    "        print(f'removed {model_fn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572888d2-dcce-4997-99a4-c2987b22b736",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe7f87-f69f-404b-82e2-59dc64d10b35",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3ForTokenClassification, LayoutLMv3Processor\n",
    "\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained('ckpt/masked/real_data/layoutlmv3_pretrained_fake_data/checkpoint-5200-best_f1-0.984-acc-0.995')\n",
    "processor = LayoutLMv3Processor.from_pretrained('microsoft/layoutlmv3-base')\n",
    "processor.tokenizer.only_label_first_subword = False\n",
    "\n",
    "print(model)\n",
    "print(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087ad1a-8c72-4cbe-8301-74468ad16968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "from transformers import LayoutXLMProcessor\n",
    "from collections import Counter\n",
    "from transformers import LayoutXLMProcessor, LayoutXLMTokenizerFast, LayoutLMv2FeatureExtractor, LayoutLMv3Processor\n",
    "\n",
    "processor = LayoutLMv3Processor.from_pretrained('microsoft/layoutlmv3-base', apply_ocr=False)\n",
    "processor.tokenizer.only_label_first_subword = False\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def denormalize(bb, img_w, img_h):\n",
    "  return (\n",
    "      int(bb[0] / 1000 * img_w),\n",
    "      int(bb[1] / 1000 * img_h),\n",
    "      int(bb[2] / 1000 * img_w),\n",
    "      int(bb[3] / 1000 * img_h),\n",
    "  )\n",
    "\n",
    "def predict(img, words, boxes):\n",
    "    assert len(words) == len(boxes)\n",
    "\n",
    "    preds_val = None\n",
    "    out_label_ids = None\n",
    "    num_no_split = 0\n",
    "    num_has_split = 0\n",
    "    result_dict = {}\n",
    "\n",
    "    img_w, img_h = img.size\n",
    "    # encode input for model\n",
    "    encoded_inputs = processor(img, words, boxes=boxes, truncation=True, stride=128,\n",
    "                               padding=\"max_length\", max_length=512, return_overflowing_tokens=True, return_offsets_mapping=True, return_tensors=\"pt\")\n",
    "    overflow_to_sample_mapping = encoded_inputs.pop('overflow_to_sample_mapping')\n",
    "    offset_mapping = encoded_inputs.pop('offset_mapping')\n",
    "\n",
    "    n = len(encoded_inputs['pixel_values'])\n",
    "    print(f'{n} split')\n",
    "\n",
    "    ls_bb2label = []\n",
    "    for idx, image in enumerate(encoded_inputs['pixel_values']):\n",
    "        # prepare input to model\n",
    "        input_ids = encoded_inputs['input_ids'][idx].unsqueeze(0).to(device)\n",
    "        bbox = encoded_inputs['bbox'][idx].unsqueeze(0).to(device)\n",
    "        image = encoded_inputs['pixel_values'][idx].unsqueeze(0).to(device)\n",
    "        attention_mask = encoded_inputs['attention_mask'][idx].unsqueeze(0).to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(input_ids=input_ids, bbox=bbox, pixel_values=image, attention_mask=attention_mask)\n",
    "\n",
    "        # process output\n",
    "        preds_val = outputs.logits.detach().cpu().numpy()[0].tolist()\n",
    "\n",
    "        bbs = bbox.detach().cpu().squeeze().numpy().tolist()\n",
    "        input_ids = input_ids.cpu().squeeze().numpy().tolist()\n",
    "        bb2label = {}\n",
    "        for i, (pred, bb) in enumerate(zip(preds_val, bbs)):\n",
    "            bb = tuple(bb)\n",
    "            if bb not in bb2label:\n",
    "              bb2label[bb] = [np.argmax(pred)]\n",
    "            else:\n",
    "              bb2label[bb].append(np.argmax(pred))\n",
    "        ls_bb2label.append(bb2label)\n",
    "\n",
    "    # get predictions for all parts\n",
    "    final_bb2label = {}\n",
    "    for bb2label in ls_bb2label:\n",
    "        for bb, label in bb2label.items():\n",
    "            if bb not in final_bb2label:\n",
    "                final_bb2label[bb] = label\n",
    "            else:\n",
    "                final_bb2label[bb].extend(label)\n",
    "\n",
    "    # get final predictions\n",
    "    bb2label = {bb: Counter(label).most_common(1)[0][0] for bb, label in final_bb2label.items()}\n",
    "\n",
    "    return {denormalize(bb, img_w, img_h): label for bb, label in bb2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe825c-06be-49c3-8082-27e07803c03c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = 'real_data/val_labeled_ocred'\n",
    "result_dict = {}\n",
    "widen_range_x = 0.1\n",
    "widen_range_y = 0.2\n",
    "for jp in Path(data_dir).rglob('*.json'):\n",
    "    img, words, boxes, labels = gen_annotation_for_img(img_fp=jp.with_suffix('.jpg'), \n",
    "                                                       json_fp=jp, \n",
    "                                                       xml_fp=jp.with_suffix('.xml'), \n",
    "                                                       masked=True,\n",
    "                                                       widen_range_x=widen_range_x,\n",
    "                                                       widen_range_y=widen_range_y)\n",
    "    result_dict[jp.with_suffix('.jpg')] = predict(img, words, boxes)\n",
    "    print(f'Done {jp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ed2ce-f8cf-4ba3-a674-11aaab7fd85f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label = model.config.id2label\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0311dc-a36a-4d0b-bb5f-8ec018e56282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "dir = 'real_data/val_labeled_ocred'\n",
    "out_dir = 'real_data/val_labeled_ocred_layoutlmv3_nonmasked_pred'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "for img_fp, bb2label in result_dict.items():\n",
    "    json_fp = img_fp.with_suffix('.json')\n",
    "    with open(json_fp, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    new_shapes = []\n",
    "    for bb, label in bb2label.items():\n",
    "        points = [\n",
    "            [bb[0], bb[1]],\n",
    "            [bb[2], bb[1]],\n",
    "            [bb[2], bb[3]],\n",
    "            [bb[0], bb[3]]\n",
    "        ]\n",
    "        shape = {\n",
    "            'label': id2label[label],\n",
    "            'points': points,\n",
    "            'shape_type': 'polygon',\n",
    "            'flags': {}\n",
    "        }\n",
    "        new_shapes.append(shape)\n",
    "    data['shapes'] = new_shapes\n",
    "\n",
    "    with open(os.path.join(out_dir, json_fp.name), 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    shutil.copy(img_fp, out_dir)\n",
    "    print(f'done {img_fp}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2a2b3f-3b2b-4bd9-a53e-00196fad3700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4b237-4b8a-43a9-9811-190fc590a7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c32c26-a6bc-4afd-8cba-43c9f2fa3f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/data/tungtx2/tmp/transformers_hub'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9775c3-2d3f-4bbe-92f4-61be2e0a0fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from os import listdir\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import unidecode\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pdb\n",
    "import xml.etree.ElementTree as ET\n",
    "from shapely.geometry import Polygon\n",
    "import cv2\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70781143-2084-43d7-9757-f9f6acb52dd8",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1387f7b9-e798-4e2a-9929-3b498fb3dc31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swift_code : 1205\n",
      "marker_swift_code : 2482\n",
      "bank_address : 6476\n",
      "marker_bank_address : 759\n",
      "bank_name : 7245\n",
      "marker_bank_name : 2218\n",
      "account_number : 1943\n",
      "marker_account_number : 2954\n",
      "marker_company_name : 3598\n",
      "text : 104778\n",
      "tax : 1316\n",
      "marker_tax : 1919\n",
      "phone : 1934\n",
      "marker_phone : 1923\n",
      "represented_name : 5742\n",
      "marker_represented_name : 1766\n",
      "marker_fax : 1888\n",
      "fax : 1931\n",
      "company_address : 9146\n",
      "marker_company_address : 1095\n",
      "company_name : 9426\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'fake_data_24032023/non_masked/train'\n",
    "val_dir = 'fake_data_24032023/non_masked/val'\n",
    "\n",
    "def find_all_labels(data_dir):\n",
    "    labels = {}\n",
    "    for jp in Path(data_dir).rglob('*.json'):\n",
    "        data = json.load(open(jp))\n",
    "        for shape in data['shapes']:\n",
    "            if shape['label'] in labels:\n",
    "                labels[shape['label']] += 1\n",
    "            else:\n",
    "                labels[shape['label']] = 0\n",
    "                \n",
    "    return labels\n",
    "\n",
    "train_labels = find_all_labels(train_dir)\n",
    "val_labels = find_all_labels(val_dir)\n",
    "assert set(train_labels.keys()) == set(val_labels.keys())\n",
    "for k, v in train_labels.items():\n",
    "    print(k, ':', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c0ca9f-184c-4657-a1bd-54e28767c841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'marker_represented_name': 0, 'marker_bank_address': 1, 'phone': 2, 'swift_code': 3, 'company_name': 4, 'marker_company_name': 5, 'marker_fax': 6, 'account_number': 7, 'marker_bank_name': 8, 'fax': 9, 'tax': 10, 'marker_account_number': 11, 'company_address': 12, 'marker_company_address': 13, 'text': 14, 'represented_name': 15, 'bank_name': 16, 'marker_phone': 17, 'bank_address': 18, 'marker_tax': 19, 'marker_swift_code': 20}\n",
      "{0: 'marker_represented_name', 1: 'marker_bank_address', 2: 'phone', 3: 'swift_code', 4: 'company_name', 5: 'marker_company_name', 6: 'marker_fax', 7: 'account_number', 8: 'marker_bank_name', 9: 'fax', 10: 'tax', 11: 'marker_account_number', 12: 'company_address', 13: 'marker_company_address', 14: 'text', 15: 'represented_name', 16: 'bank_name', 17: 'marker_phone', 18: 'bank_address', 19: 'marker_tax', 20: 'marker_swift_code'}\n"
     ]
    }
   ],
   "source": [
    "label_list = list(set(train_labels.keys()))\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id2label = {idx: label for idx, label in enumerate(label_list)}\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8cd27-63ca-460a-8b23-4ea55a874b67",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f33a90-0aef-4816-9ebf-51c77e61663f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py:33: FutureWarning: The class LayoutLMv2FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use LayoutLMv2ImageProcessor instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutXLMTokenizerFast(name_or_path='SCUT-DLVCLab/lilt-infoxlm-base', vocab_size=250002, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "LayoutLMv2FeatureExtractor {\n",
      "  \"apply_ocr\": false,\n",
      "  \"do_resize\": true,\n",
      "  \"image_processor_type\": \"LayoutLMv2FeatureExtractor\",\n",
      "  \"ocr_lang\": null,\n",
      "  \"resample\": 2,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"tesseract_config\": \"\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutXLMTokenizerFast, LayoutLMv2FeatureExtractor, LayoutXLMProcessor\n",
    "\n",
    "feature_extractor = LayoutLMv2FeatureExtractor(apply_ocr=False)\n",
    "tokenizer = LayoutXLMTokenizerFast.from_pretrained('SCUT-DLVCLab/lilt-infoxlm-base')\n",
    "tokenizer.only_label_first_subword = False\n",
    "processor = LayoutXLMProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "print(processor.tokenizer)\n",
    "print(processor.feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "630a7555-912e-4d61-a065-ba5e059f55ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_bbox(bbox, width, height):\n",
    "     return [\n",
    "         int(1000 * (bbox[0] / width)),\n",
    "         int(1000 * (bbox[1] / height)),\n",
    "         int(1000 * (bbox[2] / width)),\n",
    "         int(1000 * (bbox[3] / height)),\n",
    "     ]\n",
    "    \n",
    "    \n",
    "def parse_xml(xml_path):\n",
    "    root = ET.parse(xml_path).getroot()\n",
    "    objs = root.findall('object')\n",
    "    boxes, obj_names = [], []\n",
    "    for obj in objs:\n",
    "        obj_name = obj.find('name').text\n",
    "        box = obj.find('bndbox')\n",
    "        xmin = int(box.find('xmin').text)\n",
    "        ymin = int(box.find('ymin').text)\n",
    "        xmax = int(box.find('xmax').text)\n",
    "        ymax = int(box.find('ymax').text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        obj_names.append(obj_name)\n",
    "    return boxes, obj_names\n",
    "\n",
    "\n",
    "def widen_box(box, percent_x, percent_y):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        xmin -= w * percent_x\n",
    "        ymin -= h * percent_y\n",
    "        xmax += w * percent_x\n",
    "        ymax += h * percent_y\n",
    "        return (int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "\n",
    "    \n",
    "def draw_json_on_img(img, json_data):\n",
    "    labels = list(set(shape['label'] for shape in json_data['shapes']))\n",
    "    color = {}\n",
    "    for i in range(len(labels)):\n",
    "        color[labels[i]] = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
    "        \n",
    "    img = img.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_size = 0.5\n",
    "    for i, shape in enumerate(json_data['shapes']):\n",
    "        polys = shape['points']\n",
    "        polys = [(int(pt[0]), int(pt[1])) for pt in polys]\n",
    "        label = shape['label']\n",
    "        draw.polygon(polys, outline=color[label], width=2)\n",
    "        # Draw the text on the image\n",
    "        img = np.array(img)\n",
    "        cv2.putText(img, shape['label'], (polys[0][0], polys[0][1]-5), font, font_size, color[label], thickness=1)\n",
    "        img = Image.fromarray(img)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "    return img\n",
    "    \n",
    "    \n",
    "def mask_image(img, boxes, json_data, widen_range_x, widen_range_y):\n",
    "    # widen block\n",
    "    if isinstance(widen_range_x, list) and isinstance(widen_range_y, list):\n",
    "        boxes = [widen_box(box, np.random.uniform(widen_range_x[0], widen_range_x[1]), np.random.uniform(widen_range_y[0], widen_range_y[1])) for box in boxes]\n",
    "    else:\n",
    "        boxes = [widen_box(box, widen_range_x, widen_range_y) for box in boxes]\n",
    "        \n",
    "    \n",
    "    ls_polys2keep = []\n",
    "    ls_area2keep = []\n",
    "    iou_threshold = 0.\n",
    "    for box_idx, box in enumerate(boxes):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        box_pts = [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]\n",
    "        p_box = Polygon(box_pts)\n",
    "        for shape_idx, shape in enumerate(json_data['shapes']):\n",
    "            if shape_idx in ls_polys2keep:\n",
    "                continue\n",
    "            pts = shape['points']\n",
    "            p_shape = Polygon(pts)\n",
    "            intersect_area = p_box.intersection(p_shape).area\n",
    "            if intersect_area / p_shape.area > iou_threshold:\n",
    "                ls_polys2keep.append(shape_idx)\n",
    "                pts = [coord for pt in pts for coord in pt]\n",
    "                poly_xmin = min(pts[::2])\n",
    "                poly_ymin = min(pts[1::2])\n",
    "                poly_xmax = max(pts[::2])\n",
    "                poly_ymax = max(pts[1::2])\n",
    "                ls_area2keep.append((poly_xmin, poly_ymin, poly_xmax, poly_ymax))\n",
    "\n",
    "    # mask white all area of image that is not in block\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        xmin = max(0, xmin)\n",
    "        ymin = max(0, ymin)\n",
    "        xmax = min(img.shape[1], xmax)\n",
    "        ymax = min(img.shape[0], ymax)\n",
    "        mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "    for area2keep in ls_area2keep:\n",
    "        xmin, ymin, xmax, ymax = area2keep\n",
    "        xmin = int(max(0, xmin))\n",
    "        ymin = int(max(0, ymin))\n",
    "        xmax = int(min(img.shape[1], xmax))\n",
    "        ymax = int(min(img.shape[0], ymax))\n",
    "        mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "    # mask white\n",
    "    img[mask == 0] = 255\n",
    "\n",
    "    # delete all poly that is not in block\n",
    "    ls_idx2del = [idx for idx, shape in enumerate(json_data['shapes']) if idx not in ls_polys2keep]\n",
    "    for idx in sorted(ls_idx2del, reverse=True):\n",
    "        del json_data['shapes'][idx]\n",
    "\n",
    "    return img, json_data\n",
    "        \n",
    "\n",
    "def gen_annotation_for_img(img_fp, xml_fp, json_fp, masked=False, widen_range_x=[0.1, 0.2], widen_range_y=[0.1, 0.25]):\n",
    "    img = Image.open(img_fp).convert(\"RGB\")\n",
    "    boxes, obj_names = parse_xml(xml_fp)\n",
    "    json_data = json.load(open(json_fp))\n",
    "    \n",
    "    if masked:\n",
    "        img, json_data = mask_image(np.array(img), boxes=boxes, json_data=json_data, widen_range_x=widen_range_x, widen_range_y=widen_range_y)\n",
    "        img = Image.fromarray(img)\n",
    "    # pdb.set_trace()\n",
    "        \n",
    "    words, boxes, labels = [], [], []\n",
    "    img_h, img_w = json_data['imageHeight'], json_data['imageWidth']\n",
    "    for i, shape in enumerate(json_data['shapes']):\n",
    "      # words.append(unidecode.unidecode(shape['text'].lower()))\n",
    "      words.append(shape['text'].lower())\n",
    "      labels.append(shape['label'])\n",
    "      pts = [coord for pt in shape['points'] for coord in pt]\n",
    "      xmin = min(pts[0::2])\n",
    "      xmax = max(pts[0::2])\n",
    "      ymin = min(pts[1::2])\n",
    "      ymax = max(pts[1::2])\n",
    "\n",
    "      xmin = max(xmin, 0)\n",
    "      ymin = max(ymin, 0)\n",
    "      xmax = min(img_w, xmax)\n",
    "      ymax = min(img_h, ymax)\n",
    "\n",
    "      boxes.append(normalize_bbox((xmin, ymin, xmax, ymax), img_w, img_h))\n",
    "\n",
    "    return img, words, boxes, labels\n",
    "\n",
    "\n",
    "class CORDDataset(Dataset):\n",
    "    def __init__(self, file_paths, processor=None, max_length=512, masked=False, widen_range_x=[0.1, 0.2], widen_range_y=[0.1, 0.25]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotations (List[List]): List of lists containing the word-level annotations (words, labels, boxes).\n",
    "            image_dir (string): Directory with all the document images.\n",
    "            processor (LayoutLMv2Processor): Processor to prepare the text + image.\n",
    "        \"\"\"\n",
    "        self.ls_img_fp, self.ls_xml_fp, self.ls_json_fp = file_paths\n",
    "        assert len(self.ls_img_fp) == len(self.ls_json_fp) == len(self.ls_xml_fp)\n",
    "        self.processor = processor\n",
    "        self.masked = masked\n",
    "        self.widen_range_x = widen_range_x\n",
    "        self.widen_range_y = widen_range_y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ls_img_fp)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # first, take an image\n",
    "        img_fp = self.ls_img_fp[index]\n",
    "        xml_fp = self.ls_xml_fp[index]\n",
    "        json_fp = self.ls_json_fp[index]\n",
    "        \n",
    "        img, words, boxes, text_labels = gen_annotation_for_img(img_fp, xml_fp, json_fp, masked=self.masked, widen_range_x=self.widen_range_x, widen_range_y=self.widen_range_y)\n",
    "        idx_labels = [label2id[label] for label in text_labels]\n",
    "\n",
    "        encoded_inputs = processor(img, words, boxes=boxes, word_labels=idx_labels, truncation=True, stride =128, \n",
    "                            padding=\"max_length\", max_length=512, return_overflowing_tokens=True, return_offsets_mapping=True, return_tensors=\"pt\")  \n",
    "        \n",
    "        # print(encoded_inputs.keys())\n",
    "        overflow_to_sample_mapping = encoded_inputs.pop('overflow_to_sample_mapping')\n",
    "        offset_mapping = encoded_inputs.pop('offset_mapping')\n",
    "        encoded_inputs.pop('image')\n",
    "        # print('overflow_to_sample_mapping: ', overflow_to_sample_mapping)\n",
    "        # print('offset_mapping: ', offset_mapping)\n",
    "\n",
    "        # remove batch dimension\n",
    "        idx = np.random.randint(0, len(encoded_inputs['bbox']))\n",
    "        for k, v in encoded_inputs.items():\n",
    "            encoded_inputs[k] = v[idx]\n",
    "      \n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f086fd81-0d5e-4da6-a14a-395a0127e1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(data_dir):\n",
    "    ls_img_fp, ls_xml_fp, ls_json_fp = [], [], []\n",
    "    for img_fp in Path(data_dir).rglob('*.jpg'):\n",
    "        json_fp = img_fp.with_suffix('.json')\n",
    "        xml_fp = img_fp.with_suffix('.xml')\n",
    "        \n",
    "        ls_img_fp.append(str(img_fp))\n",
    "        ls_xml_fp.append(str(xml_fp))\n",
    "        ls_json_fp.append(str(json_fp))\n",
    "    \n",
    "    return ls_img_fp, ls_xml_fp, ls_json_fp\n",
    "\n",
    "\n",
    "train_file_paths = get_file_paths(train_dir)\n",
    "val_file_paths = get_file_paths(val_dir)\n",
    "\n",
    "widen_range_x = [0.1, 0.2]\n",
    "widen_range_y = [0.1, 0.25]\n",
    "train_dataset = CORDDataset(file_paths=train_file_paths, processor=processor, masked=False, \n",
    "                            widen_range_x=widen_range_x, widen_range_y=widen_range_y)\n",
    "val_dataset = CORDDataset(file_paths=val_file_paths, processor=processor, masked=False, \n",
    "                          widen_range_x=0.1, widen_range_y=0.15)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "577f6b1b-2981-4b24-b0c6-13c2774511c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([512])\n",
      "attention_mask torch.Size([512])\n",
      "bbox torch.Size([512, 4])\n",
      "labels torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "encoding = val_dataset[9]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dc669d9-30e8-4c77-bdd7-e7a977aee2a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('bank', 'marker_swift_code', tensor([ 27, 914,  51, 933]))\n",
      "('code', 'marker_swift_code', tensor([ 74, 912, 104, 933]))\n",
      "(':', 'marker_swift_code', tensor([ 74, 912, 104, 933]))\n",
      "(':', 'marker_swift_code', tensor([ 49, 912,  76, 935]))\n",
      "('s', 'marker_swift_code', tensor([ 49, 912,  76, 935]))\n",
      "('wi', 'marker_swift_code', tensor([ 49, 912,  76, 935]))\n",
      "('ft', 'marker_swift_code', tensor([ 49, 912,  76, 935]))\n",
      "('c', 'swift_code', tensor([105, 912, 167, 931]))\n",
      "('pm', 'swift_code', tensor([105, 912, 167, 931]))\n",
      "('ng', 'swift_code', tensor([105, 912, 167, 931]))\n",
      "('bw', 'swift_code', tensor([105, 912, 167, 931]))\n",
      "('n', 'swift_code', tensor([105, 912, 167, 931]))\n",
      "('beneficiar', 'marker_company_name', tensor([ 28, 892, 112, 912]))\n",
      "('y', 'marker_company_name', tensor([ 28, 892, 112, 912]))\n",
      "(\"'\", 'marker_company_name', tensor([ 28, 892, 112, 912]))\n",
      "('s', 'marker_company_name', tensor([ 28, 892, 112, 912]))\n",
      "('name', 'marker_company_name', tensor([123, 891, 159, 908]))\n",
      "('hl', 'company_name', tensor([170, 890, 238, 908]))\n",
      "('organi', 'company_name', tensor([170, 890, 238, 908]))\n",
      "('c', 'company_name', tensor([170, 890, 238, 908]))\n",
      "(':', 'text', tensor([159, 888, 171, 912]))\n",
      "('', 'account_number', tensor([ 87, 866, 122, 888]))\n",
      "('377', 'account_number', tensor([ 87, 866, 122, 888]))\n",
      "('866', 'account_number', tensor([ 87, 866, 122, 888]))\n",
      "('v', 'marker_account_number', tensor([ 61, 867,  81, 888]))\n",
      "('nd', 'marker_account_number', tensor([ 61, 867,  81, 888]))\n",
      "('no', 'marker_account_number', tensor([ 44, 867,  61, 888]))\n",
      "('a', 'marker_account_number', tensor([ 25, 867,  46, 888]))\n",
      "('/', 'marker_account_number', tensor([ 25, 867,  46, 888]))\n",
      "('c', 'marker_account_number', tensor([ 25, 867,  46, 888]))\n",
      "('1:', 'text', tensor([ 80, 867,  87, 886]))\n",
      "('re', 'bank_address', tensor([ 70, 846, 121, 863]))\n",
      "('voor', 'bank_address', tensor([ 70, 846, 121, 863]))\n",
      "('t', 'bank_address', tensor([ 70, 846, 121, 863]))\n",
      "('l', 'bank_address', tensor([ 70, 846, 121, 863]))\n",
      "('n', 'bank_address', tensor([ 70, 846, 121, 863]))\n",
      "('.', 'bank_address', tensor([ 70, 846, 121, 863]))\n",
      "('', 'text', tensor([ 56, 849,  61, 862]))\n",
      "(',', 'text', tensor([ 56, 849,  61, 862]))\n",
      "('add', 'marker_bank_address', tensor([ 24, 844,  52, 867]))\n",
      "('75', 'bank_address', tensor([130, 844, 164, 862]))\n",
      "('73', 'bank_address', tensor([130, 844, 164, 862]))\n",
      "('ct', 'bank_address', tensor([130, 844, 164, 862]))\n",
      "('over', 'bank_address', tensor([222, 843, 270, 860]))\n",
      "('ijs', 'bank_address', tensor([222, 843, 270, 860]))\n",
      "('sel', 'bank_address', tensor([222, 843, 270, 860]))\n",
      "('old', 'bank_address', tensor([166, 843, 214, 862]))\n",
      "('enza', 'bank_address', tensor([166, 843, 214, 862]))\n",
      "('al', 'bank_address', tensor([166, 843, 214, 862]))\n",
      "('7', 'bank_address', tensor([121, 844, 131, 862]))\n",
      "('beneficiar', 'marker_bank_name', tensor([ 25, 822,  80, 839]))\n",
      "('y', 'marker_bank_name', tensor([ 25, 822,  80, 839]))\n",
      "('banker', 'marker_bank_name', tensor([ 90, 821, 135, 839]))\n",
      "(\"'\", 'marker_bank_name', tensor([ 90, 821, 135, 839]))\n",
      "('s', 'marker_bank_name', tensor([ 90, 821, 135, 839]))\n",
      "('name', 'marker_bank_name', tensor([137, 820, 169, 839]))\n",
      "(':', 'marker_bank_name', tensor([137, 820, 169, 839]))\n",
      "('of', 'bank_name', tensor([200, 818, 255, 837]))\n",
      "('china', 'bank_name', tensor([200, 818, 255, 837]))\n",
      "('bank', 'bank_name', tensor([170, 818, 202, 837]))\n",
      "('5.2', 'text', tensor([107, 705, 169, 724]))\n",
      "('.', 'text', tensor([107, 705, 169, 724]))\n",
      "('un', 'text', tensor([107, 705, 169, 724]))\n",
      "('realiz', 'text', tensor([107, 705, 169, 724]))\n",
      "('ed', 'text', tensor([107, 705, 169, 724]))\n",
      "('profit', 'text', tensor([169, 704, 193, 723]))\n",
      "('9.', 'text', tensor([258, 702, 316, 719]))\n",
      "('39', 'text', tensor([258, 702, 316, 719]))\n",
      "('7.7', 'text', tensor([258, 702, 316, 719]))\n",
      "('27', 'text', tensor([258, 702, 316, 719]))\n",
      "('.', 'text', tensor([258, 702, 316, 719]))\n",
      "('110', 'text', tensor([258, 702, 316, 719]))\n",
      "('118', 'text', tensor([335, 701, 402, 718]))\n",
      "('.', 'text', tensor([335, 701, 402, 718]))\n",
      "('98', 'text', tensor([335, 701, 402, 718]))\n",
      "('3.3', 'text', tensor([335, 701, 402, 718]))\n",
      "('31', 'text', tensor([335, 701, 402, 718]))\n",
      "('.', 'text', tensor([335, 701, 402, 718]))\n",
      "('389', 'text', tensor([335, 701, 402, 718]))\n",
      "('17', 'text', tensor([415, 696, 484, 718]))\n",
      "('1,4', 'text', tensor([415, 696, 484, 718]))\n",
      "('05', 'text', tensor([415, 696, 484, 718]))\n",
      "(',', 'text', tensor([415, 696, 484, 718]))\n",
      "('43', 'text', tensor([415, 696, 484, 718]))\n",
      "('6,9', 'text', tensor([415, 696, 484, 718]))\n",
      "('84', 'text', tensor([415, 696, 484, 718]))\n",
      "('(19', 'text', tensor([498, 695, 570, 715]))\n",
      "('4.4', 'text', tensor([498, 695, 570, 715]))\n",
      "('14', 'text', tensor([498, 695, 570, 715]))\n",
      "('.', 'text', tensor([498, 695, 570, 715]))\n",
      "('8', 'text', tensor([498, 695, 570, 715]))\n",
      "('16', 'text', tensor([498, 695, 570, 715]))\n",
      "('.', 'text', tensor([498, 695, 570, 715]))\n",
      "('0', 'text', tensor([498, 695, 570, 715]))\n",
      "('28)', 'text', tensor([498, 695, 570, 715]))\n",
      "('15', 'text', tensor([592, 693, 654, 712]))\n",
      "('1.6', 'text', tensor([592, 693, 654, 712]))\n",
      "('54', 'text', tensor([592, 693, 654, 712]))\n",
      "('.', 'text', tensor([592, 693, 654, 712]))\n",
      "('370', 'text', tensor([592, 693, 654, 712]))\n",
      "('.', 'text', tensor([592, 693, 654, 712]))\n",
      "('157', 'text', tensor([592, 693, 654, 712]))\n",
      "('(29', 'text', tensor([670, 689, 746, 712]))\n",
      "('9.6', 'text', tensor([670, 689, 746, 712]))\n",
      "('47', 'text', tensor([670, 689, 746, 712]))\n",
      "('.', 'text', tensor([670, 689, 746, 712]))\n",
      "('380', 'text', tensor([670, 689, 746, 712]))\n",
      "('.', 'text', tensor([670, 689, 746, 712]))\n",
      "('3', 'text', tensor([670, 689, 746, 712]))\n",
      "('15)', 'text', tensor([670, 689, 746, 712]))\n",
      "('realized', 'text', tensor([123, 691, 160, 708]))\n",
      "('5.1', 'text', tensor([108, 693, 123, 708]))\n",
      "('.', 'text', tensor([108, 693, 123, 708]))\n",
      "('(1', 'text', tensor([764, 688, 834, 709]))\n",
      "('3.6', 'text', tensor([764, 688, 834, 709]))\n",
      "('11', 'text', tensor([764, 688, 834, 709]))\n",
      "('.', 'text', tensor([764, 688, 834, 709]))\n",
      "('65', 'text', tensor([764, 688, 834, 709]))\n",
      "('1.9', 'text', tensor([764, 688, 834, 709]))\n",
      "('34)', 'text', tensor([764, 688, 834, 709]))\n",
      "('profit', 'text', tensor([161, 689, 184, 708]))\n",
      "('(29', 'text', tensor([858, 686, 929, 706]))\n",
      "('.', 'text', tensor([858, 686, 929, 706]))\n",
      "('009', 'text', tensor([858, 686, 929, 706]))\n",
      "('.', 'text', tensor([858, 686, 929, 706]))\n",
      "('67', 'text', tensor([858, 686, 929, 706]))\n",
      "('8.7', 'text', tensor([858, 686, 929, 706]))\n",
      "('69)', 'text', tensor([858, 686, 929, 706]))\n",
      "('850', 'text', tensor([283, 687, 316, 704]))\n",
      "(',', 'text', tensor([283, 687, 316, 704]))\n",
      "('208', 'text', tensor([283, 687, 316, 704]))\n",
      "('2.4', 'text', tensor([240, 687, 284, 706]))\n",
      "('93', 'text', tensor([240, 687, 284, 706]))\n",
      "(',', 'text', tensor([240, 687, 284, 706]))\n",
      "('351', 'text', tensor([240, 687, 284, 706]))\n",
      "(',', 'text', tensor([240, 687, 284, 706]))\n",
      "('2.', 'text', tensor([325, 683, 403, 704]))\n",
      "('577', 'text', tensor([325, 683, 403, 704]))\n",
      "('.', 'text', tensor([325, 683, 403, 704]))\n",
      "('92', 'text', tensor([325, 683, 403, 704]))\n",
      "('7.0', 'text', tensor([325, 683, 403, 704]))\n",
      "('84', 'text', tensor([325, 683, 403, 704]))\n",
      "('.', 'text', tensor([325, 683, 403, 704]))\n",
      "('160', 'text', tensor([325, 683, 403, 704]))\n",
      "('1.0', 'text', tensor([409, 680, 484, 702]))\n",
      "('15', 'text', tensor([409, 680, 484, 702]))\n",
      "('.', 'text', tensor([409, 680, 484, 702]))\n",
      "('36', 'text', tensor([409, 680, 484, 702]))\n",
      "('2.0', 'text', tensor([409, 680, 484, 702]))\n",
      "('45', 'text', tensor([409, 680, 484, 702]))\n",
      "('.', 'text', tensor([409, 680, 484, 702]))\n",
      "('653', 'text', tensor([409, 680, 484, 702]))\n",
      "('(', 'text', tensor([498, 679, 570, 700]))\n",
      "('84', 'text', tensor([498, 679, 570, 700]))\n",
      "('3.9', 'text', tensor([498, 679, 570, 700]))\n",
      "('19', 'text', tensor([498, 679, 570, 700]))\n",
      "('.', 'text', tensor([498, 679, 570, 700]))\n",
      "('21', 'text', tensor([498, 679, 570, 700]))\n",
      "('0.3', 'text', tensor([498, 679, 570, 700]))\n",
      "('24)', 'text', tensor([498, 679, 570, 700]))\n",
      "('1.', 'text', tensor([585, 678, 638, 696]))\n",
      "('740', 'text', tensor([585, 678, 638, 696]))\n",
      "('.', 'text', tensor([585, 678, 638, 696]))\n",
      "('98', 'text', tensor([585, 678, 638, 696]))\n",
      "('4.0', 'text', tensor([585, 678, 638, 696]))\n",
      "('25', 'text', tensor([585, 678, 638, 696]))\n",
      "('', 'text', tensor([689, 676, 709, 695]))\n",
      "(',', 'text', tensor([689, 676, 709, 695]))\n",
      "('551', 'text', tensor([689, 676, 709, 695]))\n",
      "(',', 'text', tensor([689, 676, 709, 695]))\n",
      "('t', 'text', tensor([661, 675, 693, 697]))\n",
      "('1.1', 'text', tensor([661, 675, 693, 697]))\n",
      "('79', 'text', tensor([661, 675, 693, 697]))\n",
      "(',', 'text', tensor([661, 675, 693, 697]))\n",
      "('', 'text', tensor([638, 676, 654, 696]))\n",
      "(',', 'text', tensor([638, 676, 654, 696]))\n",
      "('106', 'text', tensor([638, 676, 654, 696]))\n",
      "('2.', 'text', tensor([756, 674, 784, 693]))\n",
      "('664', 'text', tensor([756, 674, 784, 693]))\n",
      "(',', 'text', tensor([756, 674, 784, 693]))\n",
      "('3', 'text', tensor([725, 674, 746, 693]))\n",
      "('59)', 'text', tensor([725, 674, 746, 693]))\n",
      "('s', 'text', tensor([707, 674, 728, 693]))\n",
      "('28', 'text', tensor([707, 674, 728, 693]))\n",
      "('.', 'text', tensor([707, 674, 728, 693]))\n",
      "('profit', 'text', tensor([121, 673, 146, 697]))\n",
      "('pri', 'text', tensor([916, 671, 929, 688]))\n",
      "('58', 'text', tensor([894, 674, 918, 687]))\n",
      "('0.9', 'text', tensor([894, 674, 918, 687]))\n",
      "('3', 'text', tensor([847, 672, 876, 691]))\n",
      "(',', 'text', tensor([847, 672, 876, 691]))\n",
      "('139', 'text', tensor([847, 672, 876, 691]))\n",
      "(',', 'text', tensor([847, 672, 876, 691]))\n",
      "('', 'text', tensor([782, 672, 834, 691]))\n",
      "('794', 'text', tensor([782, 672, 834, 691]))\n",
      "('.', 'text', tensor([782, 672, 834, 691]))\n",
      "('685', 'text', tensor([782, 672, 834, 691]))\n",
      "('.', 'text', tensor([782, 672, 834, 691]))\n",
      "('537', 'text', tensor([782, 672, 834, 691]))\n",
      "('', 'text', tensor([873, 671, 894, 689]))\n",
      "('359', 'text', tensor([873, 671, 894, 689]))\n",
      "('2,5', 'text', tensor([239, 671, 315, 690]))\n",
      "('02', 'text', tensor([239, 671, 315, 690]))\n",
      "(',', 'text', tensor([239, 671, 315, 690]))\n",
      "('749', 'text', tensor([239, 671, 315, 690]))\n",
      "(',', 'text', tensor([239, 671, 315, 690]))\n",
      "('577', 'text', tensor([239, 671, 315, 690]))\n",
      "(',', 'text', tensor([239, 671, 315, 690]))\n",
      "('3', 'text', tensor([239, 671, 315, 690]))\n",
      "('18', 'text', tensor([239, 671, 315, 690]))\n",
      "('2', 'text', tensor([325, 666, 400, 689]))\n",
      "(',', 'text', tensor([325, 666, 400, 689]))\n",
      "('69', 'text', tensor([325, 666, 400, 689]))\n",
      "('6,9', 'text', tensor([325, 666, 400, 689]))\n",
      "('10', 'text', tensor([325, 666, 400, 689]))\n",
      "(',', 'text', tensor([325, 666, 400, 689]))\n",
      "('4', 'text', tensor([325, 666, 400, 689]))\n",
      "('15', 'text', tensor([325, 666, 400, 689]))\n",
      "(',', 'text', tensor([325, 666, 400, 689]))\n",
      "('549', 'text', tensor([325, 666, 400, 689]))\n",
      "('1,1', 'text', tensor([406, 666, 481, 687]))\n",
      "('86', 'text', tensor([406, 666, 481, 687]))\n",
      "(',', 'text', tensor([406, 666, 481, 687]))\n",
      "('767', 'text', tensor([406, 666, 481, 687]))\n",
      "(',', 'text', tensor([406, 666, 481, 687]))\n",
      "('48', 'text', tensor([406, 666, 481, 687]))\n",
      "('2,6', 'text', tensor([406, 666, 481, 687]))\n",
      "('37', 'text', tensor([406, 666, 481, 687]))\n",
      "('(', 'text', tensor([489, 665, 570, 684]))\n",
      "('1.0', 'text', tensor([489, 665, 570, 684]))\n",
      "('38', 'text', tensor([489, 665, 570, 684]))\n",
      "(',', 'text', tensor([489, 665, 570, 684]))\n",
      "('334', 'text', tensor([489, 665, 570, 684]))\n",
      "(',', 'text', tensor([489, 665, 570, 684]))\n",
      "('02', 'text', tensor([489, 665, 570, 684]))\n",
      "('6', 'text', tensor([489, 665, 570, 684]))\n",
      "(',', 'text', tensor([489, 665, 570, 684]))\n",
      "('3', 'text', tensor([489, 665, 570, 684]))\n",
      "('52)', 'text', tensor([489, 665, 570, 684]))\n",
      "('(1', 'text', tensor([661, 661, 691, 680]))\n",
      "(',', 'text', tensor([661, 661, 691, 680]))\n",
      "('479', 'text', tensor([661, 661, 691, 680]))\n",
      "(',', 'text', tensor([661, 661, 691, 680]))\n",
      "('1,8', 'text', tensor([583, 661, 654, 682]))\n",
      "('92', 'text', tensor([583, 661, 654, 682]))\n",
      "(',', 'text', tensor([583, 661, 654, 682]))\n",
      "('638', 'text', tensor([583, 661, 654, 682]))\n",
      "(',', 'text', tensor([583, 661, 654, 682]))\n",
      "('395', 'text', tensor([583, 661, 654, 682]))\n",
      "(',', 'text', tensor([583, 661, 654, 682]))\n",
      "('26', 'text', tensor([583, 661, 654, 682]))\n",
      "('3', 'text', tensor([583, 661, 654, 682]))\n",
      "('2,6', 'text', tensor([756, 660, 782, 678]))\n",
      "('51', 'text', tensor([756, 660, 782, 678]))\n",
      "('19', 'text', tensor([690, 660, 746, 679]))\n",
      "('8,9', 'text', tensor([690, 660, 746, 679]))\n",
      "('08', 'text', tensor([690, 660, 746, 679]))\n",
      "(',', 'text', tensor([690, 660, 746, 679]))\n",
      "('6', 'text', tensor([690, 660, 746, 679]))\n",
      "('74)', 'text', tensor([690, 660, 746, 679]))\n",
      "('und', 'text', tensor([123, 660, 178, 678]))\n",
      "('is', 'text', tensor([123, 660, 178, 678]))\n",
      "('tribute', 'text', tensor([123, 660, 178, 678]))\n",
      "('d', 'text', tensor([123, 660, 178, 678]))\n",
      "('1', 'text', tensor([104, 660, 117, 679]))\n",
      "('3.', 'text', tensor([847, 657, 893, 674]))\n",
      "('110', 'text', tensor([847, 657, 893, 674]))\n",
      "('.', 'text', tensor([847, 657, 893, 674]))\n",
      "('349', 'text', tensor([847, 657, 893, 674]))\n",
      "('', 'text', tensor([781, 656, 833, 677]))\n",
      "(',', 'text', tensor([781, 656, 833, 677]))\n",
      "('18', 'text', tensor([781, 656, 833, 677]))\n",
      "('3,0', 'text', tensor([781, 656, 833, 677]))\n",
      "('33', 'text', tensor([781, 656, 833, 677]))\n",
      "(',', 'text', tensor([781, 656, 833, 677]))\n",
      "('60', 'text', tensor([781, 656, 833, 677]))\n",
      "('3', 'text', tensor([781, 656, 833, 677]))\n",
      "('', 'text', tensor([892, 655, 912, 674]))\n",
      "(',', 'text', tensor([892, 655, 912, 674]))\n",
      "('90', 'text', tensor([892, 655, 912, 674]))\n",
      "('2', 'text', tensor([892, 655, 912, 674]))\n",
      "(',', 'text', tensor([892, 655, 912, 674]))\n",
      "('', 'text', tensor([911, 654, 929, 672]))\n",
      "('.', 'text', tensor([911, 654, 929, 672]))\n",
      "('138', 'text', tensor([911, 654, 929, 672]))\n",
      "('fair', 'text', tensor([132, 644, 148, 665]))\n",
      "('at', 'text', tensor([122, 646, 132, 663]))\n",
      "('value', 'text', tensor([148, 643, 172, 663]))\n",
      "('(3', 'text', tensor([251, 640, 314, 660]))\n",
      "(',', 'text', tensor([251, 640, 314, 660]))\n",
      "('79', 'text', tensor([251, 640, 314, 660]))\n",
      "('3,0', 'text', tensor([251, 640, 314, 660]))\n",
      "('33', 'text', tensor([251, 640, 314, 660]))\n",
      "(',', 'text', tensor([251, 640, 314, 660]))\n",
      "('106', 'text', tensor([251, 640, 314, 660]))\n",
      "(')', 'text', tensor([251, 640, 314, 660]))\n",
      "('(3', 'text', tensor([336, 638, 400, 659]))\n",
      "(',', 'text', tensor([336, 638, 400, 659]))\n",
      "('79', 'text', tensor([336, 638, 400, 659]))\n",
      "('3,0', 'text', tensor([336, 638, 400, 659]))\n",
      "('33', 'text', tensor([336, 638, 400, 659]))\n",
      "(',', 'text', tensor([336, 638, 400, 659]))\n",
      "('106', 'text', tensor([336, 638, 400, 659]))\n",
      "(')', 'text', tensor([336, 638, 400, 659]))\n",
      "('financial', 'text', tensor([122, 631, 158, 646]))\n",
      "('(3', 'text', tensor([768, 629, 832, 646]))\n",
      "('.', 'text', tensor([768, 629, 832, 646]))\n",
      "('79', 'text', tensor([768, 629, 832, 646]))\n",
      "('3,0', 'text', tensor([768, 629, 832, 646]))\n",
      "('33', 'text', tensor([768, 629, 832, 646]))\n",
      "(',', 'text', tensor([768, 629, 832, 646]))\n",
      "('106', 'text', tensor([768, 629, 832, 646]))\n",
      "(')', 'text', tensor([768, 629, 832, 646]))\n",
      "('assets', 'text', tensor([158, 628, 187, 648]))\n",
      "('(3', 'text', tensor([859, 625, 928, 645]))\n",
      "(',', 'text', tensor([859, 625, 928, 645]))\n",
      "('79', 'text', tensor([859, 625, 928, 645]))\n",
      "('3,0', 'text', tensor([859, 625, 928, 645]))\n",
      "('33', 'text', tensor([859, 625, 928, 645]))\n",
      "(',', 'text', tensor([859, 625, 928, 645]))\n",
      "('106', 'text', tensor([859, 625, 928, 645]))\n",
      "(')', 'text', tensor([859, 625, 928, 645]))\n",
      "('re', 'text', tensor([122, 614, 168, 632]))\n",
      "('valu', 'text', tensor([122, 614, 168, 632]))\n",
      "('ation', 'text', tensor([122, 614, 168, 632]))\n",
      "('of', 'text', tensor([170, 614, 179, 632]))\n",
      "('from', 'text', tensor([121, 599, 143, 616]))\n",
      "('difference', 'text', tensor([121, 585, 169, 601]))\n",
      "('s', 'text', tensor([121, 585, 169, 601]))\n",
      "('4.', 'text', tensor([107, 588, 113, 599]))\n",
      "('reserve', 'text', tensor([121, 569, 153, 586]))\n",
      "('', 'text', tensor([246, 564, 314, 584]))\n",
      "('434', 'text', tensor([246, 564, 314, 584]))\n",
      "(',', 'text', tensor([246, 564, 314, 584]))\n",
      "('679', 'text', tensor([246, 564, 314, 584]))\n",
      "(',', 'text', tensor([246, 564, 314, 584]))\n",
      "('749', 'text', tensor([246, 564, 314, 584]))\n",
      "(',', 'text', tensor([246, 564, 314, 584]))\n",
      "('965', 'text', tensor([246, 564, 314, 584]))\n",
      "('', 'text', tensor([330, 563, 400, 580]))\n",
      "('492', 'text', tensor([330, 563, 400, 580]))\n",
      "('.', 'text', tensor([330, 563, 400, 580]))\n",
      "('93', 'text', tensor([330, 563, 400, 580]))\n",
      "('2', 'text', tensor([330, 563, 400, 580]))\n",
      "(',', 'text', tensor([330, 563, 400, 580]))\n",
      "('169', 'text', tensor([330, 563, 400, 580]))\n",
      "('.', 'text', tensor([330, 563, 400, 580]))\n",
      "('472', 'text', tensor([330, 563, 400, 580]))\n",
      "('58', 'text', tensor([418, 562, 480, 579]))\n",
      "('.', 'text', tensor([418, 562, 480, 579]))\n",
      "('25', 'text', tensor([418, 562, 480, 579]))\n",
      "('2.4', 'text', tensor([418, 562, 480, 579]))\n",
      "('19', 'text', tensor([418, 562, 480, 579]))\n",
      "('.', 'text', tensor([418, 562, 480, 579]))\n",
      "('507', 'text', tensor([418, 562, 480, 579]))\n",
      "('(', 'text', tensor([666, 556, 744, 573]))\n",
      "('492', 'text', tensor([666, 556, 744, 573]))\n",
      "(',', 'text', tensor([666, 556, 744, 573]))\n",
      "('93', 'text', tensor([666, 556, 744, 573]))\n",
      "('2', 'text', tensor([666, 556, 744, 573]))\n",
      "(',', 'text', tensor([666, 556, 744, 573]))\n",
      "('169', 'text', tensor([666, 556, 744, 573]))\n",
      "(',', 'text', tensor([666, 556, 744, 573]))\n",
      "('472', 'text', tensor([666, 556, 744, 573]))\n",
      "(')', 'text', tensor([666, 556, 744, 573]))\n",
      "('financial', 'text', tensor([140, 554, 175, 571]))\n",
      "('and', 'text', tensor([120, 554, 138, 573]))\n",
      "('', 'text', tensor([764, 551, 832, 572]))\n",
      "('492', 'text', tensor([764, 551, 832, 572]))\n",
      "(',', 'text', tensor([764, 551, 832, 572]))\n",
      "('93', 'text', tensor([764, 551, 832, 572]))\n",
      "('2', 'text', tensor([764, 551, 832, 572]))\n",
      "(',', 'text', tensor([764, 551, 832, 572]))\n",
      "('169', 'text', tensor([764, 551, 832, 572]))\n",
      "(',', 'text', tensor([764, 551, 832, 572]))\n",
      "('472', 'text', tensor([764, 551, 832, 572]))\n",
      "('operation', 'text', tensor([121, 538, 170, 556]))\n",
      "('al', 'text', tensor([121, 538, 170, 556]))\n",
      "('risk', 'text', tensor([170, 537, 188, 557]))\n",
      "('reserve', 'text', tensor([122, 524, 152, 541]))\n",
      "('5', 'text', tensor([244, 519, 314, 539]))\n",
      "('19', 'text', tensor([244, 519, 314, 539]))\n",
      "(',', 'text', tensor([244, 519, 314, 539]))\n",
      "('187', 'text', tensor([244, 519, 314, 539]))\n",
      "(',', 'text', tensor([244, 519, 314, 539]))\n",
      "('344', 'text', tensor([244, 519, 314, 539]))\n",
      "(',', 'text', tensor([244, 519, 314, 539]))\n",
      "('649', 'text', tensor([244, 519, 314, 539]))\n",
      "('58', 'text', tensor([335, 516, 398, 537]))\n",
      "(',', 'text', tensor([335, 516, 398, 537]))\n",
      "('25', 'text', tensor([335, 516, 398, 537]))\n",
      "('2', 'text', tensor([335, 516, 398, 537]))\n",
      "(',', 'text', tensor([335, 516, 398, 537]))\n",
      "('41', 'text', tensor([335, 516, 398, 537]))\n",
      "('9,5', 'text', tensor([335, 516, 398, 537]))\n",
      "('07', 'text', tensor([335, 516, 398, 537]))\n",
      "('58', 'text', tensor([418, 517, 479, 534]))\n",
      "(',', 'text', tensor([418, 517, 479, 534]))\n",
      "('25', 'text', tensor([418, 517, 479, 534]))\n",
      "('2', 'text', tensor([418, 517, 479, 534]))\n",
      "(',', 'text', tensor([418, 517, 479, 534]))\n",
      "('41', 'text', tensor([418, 517, 479, 534]))\n",
      "('9,5', 'text', tensor([418, 517, 479, 534]))\n",
      "('07', 'text', tensor([418, 517, 479, 534]))\n",
      "('supplement', 'text', tensor([120, 507, 182, 527]))\n",
      "('ary', 'text', tensor([120, 507, 182, 527]))\n",
      "('', 'text', tensor([762, 506, 830, 526]))\n",
      "('577', 'text', tensor([762, 506, 830, 526]))\n",
      "(',', 'text', tensor([762, 506, 830, 526]))\n",
      "('439', 'text', tensor([762, 506, 830, 526]))\n",
      "(',', 'text', tensor([762, 506, 830, 526]))\n",
      "('764', 'text', tensor([762, 506, 830, 526]))\n",
      "(',', 'text', tensor([762, 506, 830, 526]))\n",
      "('156', 'text', tensor([762, 506, 830, 526]))\n",
      "('58', 'text', tensor([859, 503, 925, 523]))\n",
      "(',', 'text', tensor([859, 503, 925, 523]))\n",
      "('25', 'text', tensor([859, 503, 925, 523]))\n",
      "('2', 'text', tensor([859, 503, 925, 523]))\n",
      "(',', 'text', tensor([859, 503, 925, 523]))\n",
      "('41', 'text', tensor([859, 503, 925, 523]))\n",
      "('9,5', 'text', tensor([859, 503, 925, 523]))\n",
      "('07', 'text', tensor([859, 503, 925, 523]))\n",
      "('charter', 'text', tensor([120, 493, 151, 510]))\n",
      "('2.', 'text', tensor([104, 494, 114, 510]))\n",
      "('capital', 'text', tensor([153, 491, 182, 510]))\n",
      "('tre', 'text', tensor([121, 479, 158, 494]))\n",
      "('as', 'text', tensor([121, 479, 158, 494]))\n",
      "('ury', 'text', tensor([121, 479, 158, 494]))\n",
      "('share', 'text', tensor([159, 477, 184, 494]))\n",
      "('1.4', 'text', tensor([104, 477, 121, 496]))\n",
      "('.', 'text', tensor([104, 477, 121, 496]))\n",
      "('(21', 'text', tensor([330, 472, 398, 489]))\n",
      "('.', 'text', tensor([330, 472, 398, 489]))\n",
      "('98', 'text', tensor([330, 472, 398, 489]))\n",
      "('3.9', 'text', tensor([330, 472, 398, 489]))\n",
      "('12', 'text', tensor([330, 472, 398, 489]))\n",
      "('.', 'text', tensor([330, 472, 398, 489]))\n",
      "('738', 'text', tensor([330, 472, 398, 489]))\n",
      "(')', 'text', tensor([330, 472, 398, 489]))\n",
      "('(', 'text', tensor([243, 471, 314, 495]))\n",
      "('34', 'text', tensor([243, 471, 314, 495]))\n",
      "('.', 'text', tensor([243, 471, 314, 495]))\n",
      "('661', 'text', tensor([243, 471, 314, 495]))\n",
      "('.', 'text', tensor([243, 471, 314, 495]))\n",
      "('96', 'text', tensor([243, 471, 314, 495]))\n",
      "('2.', 'text', tensor([243, 471, 314, 495]))\n",
      "('785', 'text', tensor([243, 471, 314, 495]))\n",
      "(')', 'text', tensor([243, 471, 314, 495]))\n",
      "('(', 'text', tensor([422, 468, 480, 489]))\n",
      "('459', 'text', tensor([422, 468, 480, 489]))\n",
      "('.', 'text', tensor([422, 468, 480, 489]))\n",
      "('4', 'text', tensor([422, 468, 480, 489]))\n",
      "('47', 'text', tensor([422, 468, 480, 489]))\n",
      "('.', 'text', tensor([422, 468, 480, 489]))\n",
      "('500', 'text', tensor([422, 468, 480, 489]))\n",
      "(')', 'text', tensor([422, 468, 480, 489]))\n",
      "('13.', 'text', tensor([503, 463, 571, 489]))\n",
      "('82', 'text', tensor([503, 463, 571, 489]))\n",
      "('7.8', 'text', tensor([503, 463, 571, 489]))\n",
      "('09.', 'text', tensor([503, 463, 571, 489]))\n",
      "('09', 'text', tensor([503, 463, 571, 489]))\n",
      "('7', 'text', tensor([503, 463, 571, 489]))\n",
      "('(1', 'text', tensor([583, 465, 650, 483]))\n",
      "('.', 'text', tensor([583, 465, 650, 483]))\n",
      "('33', 'text', tensor([583, 465, 650, 483]))\n",
      "('0.7', 'text', tensor([583, 465, 650, 483]))\n",
      "('10', 'text', tensor([583, 465, 650, 483]))\n",
      "('.', 'text', tensor([583, 465, 650, 483]))\n",
      "('900', 'text', tensor([583, 465, 650, 483]))\n",
      "(')', 'text', tensor([583, 465, 650, 483]))\n",
      "('component', 'text', tensor([119, 462, 167, 482]))\n",
      "('(21', 'text', tensor([762, 460, 830, 481]))\n",
      "(',', 'text', tensor([762, 460, 830, 481]))\n",
      "('29', 'text', tensor([762, 460, 830, 481]))\n",
      "('3', 'text', tensor([762, 460, 830, 481]))\n",
      "(',', 'text', tensor([762, 460, 830, 481]))\n",
      "('601', 'text', tensor([762, 460, 830, 481]))\n",
      "(',', 'text', tensor([762, 460, 830, 481]))\n",
      "('188', 'text', tensor([762, 460, 830, 481]))\n",
      "(')', 'text', tensor([762, 460, 830, 481]))\n",
      "('4', 'text', tensor([680, 460, 744, 483]))\n",
      "(',', 'text', tensor([680, 460, 744, 483]))\n",
      "('2', 'text', tensor([680, 460, 744, 483]))\n",
      "('36', 'text', tensor([680, 460, 744, 483]))\n",
      "(',', 'text', tensor([680, 460, 744, 483]))\n",
      "('13', 'text', tensor([680, 460, 744, 483]))\n",
      "('5,7', 'text', tensor([680, 460, 744, 483]))\n",
      "('29', 'text', tensor([680, 460, 744, 483]))\n",
      "('(19', 'text', tensor([853, 458, 925, 478]))\n",
      "(',', 'text', tensor([853, 458, 925, 478]))\n",
      "('07', 'text', tensor([853, 458, 925, 478]))\n",
      "('8', 'text', tensor([853, 458, 925, 478]))\n",
      "(',', 'text', tensor([853, 458, 925, 478]))\n",
      "('48', 'text', tensor([853, 458, 925, 478]))\n",
      "('7,9', 'text', tensor([853, 458, 925, 478]))\n",
      "('09)', 'text', tensor([853, 458, 925, 478]))\n",
      "('113', 'text', tensor([243, 457, 314, 477]))\n",
      "(',', 'text', tensor([243, 457, 314, 477]))\n",
      "('779', 'text', tensor([243, 457, 314, 477]))\n",
      "(',', 'text', tensor([243, 457, 314, 477]))\n",
      "('09', 'text', tensor([243, 457, 314, 477]))\n",
      "('5,7', 'text', tensor([243, 457, 314, 477]))\n",
      "('85', 'text', tensor([243, 457, 314, 477]))\n",
      "('(', 'text', tensor([492, 449, 549, 472]))\n",
      "('113', 'text', tensor([492, 449, 549, 472]))\n",
      "('.', 'text', tensor([492, 449, 549, 472]))\n",
      "('779', 'text', tensor([492, 449, 549, 472]))\n",
      "('.', 'text', tensor([492, 449, 549, 472]))\n",
      "('09', 'text', tensor([492, 449, 549, 472]))\n",
      "('5', 'text', tensor([492, 449, 549, 472]))\n",
      "('</s>', 'SPECIAL', tensor([1000, 1000, 1000, 1000]))\n"
     ]
    }
   ],
   "source": [
    "ls_token = [processor.tokenizer.decode(input_id) for input_id in encoding['input_ids']]\n",
    "ls_label = [id2label[int(label_id)] if label_id != -100 else 'SPECIAL' for label_id in encoding['labels'] ]\n",
    "ls_bb = list(encoding['bbox'])\n",
    "for item in zip(ls_token, ls_label, ls_bb):\n",
    "  print(item)\n",
    "  # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892721ca-6813-44c3-825f-63bb6b7105a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([4, 512])\n",
      "attention_mask torch.Size([4, 512])\n",
      "bbox torch.Size([4, 512, 4])\n",
      "labels torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "for item in train_dataloader:\n",
    "  for k, v in item.items():\n",
    "    print(k, v.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fbc27-8f78-4ffc-8eba-4b6682de8f24",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4473d92-f536-487e-9ec7-6884ee8a5001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LiltForTokenClassification were not initialized from the model checkpoint at SCUT-DLVCLab/lilt-infoxlm-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LiltForTokenClassification\n",
    "\n",
    "model = LiltForTokenClassification.from_pretrained('SCUT-DLVCLab/lilt-infoxlm-base', id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e97bd98-c0fc-4e06-bb14-1416e07b75fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LiltForTokenClassification(\n",
       "  (lilt): LiltModel(\n",
       "    (embeddings): LiltTextEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layout_embeddings): LiltLayoutEmbeddings(\n",
       "      (x_position_embeddings): Embedding(1024, 128)\n",
       "      (y_position_embeddings): Embedding(1024, 128)\n",
       "      (h_position_embeddings): Embedding(1024, 128)\n",
       "      (w_position_embeddings): Embedding(1024, 128)\n",
       "      (box_position_embeddings): Embedding(514, 192, padding_idx=1)\n",
       "      (box_linear_embeddings): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LiltEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b09c3-6b46-40d2-9f6f-8dacb10125b6",
   "metadata": {},
   "source": [
    "# Hugging Face Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8d51543-f98b-4124-bfc4-252177e4e0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marker_represented_name',\n",
       " 'marker_bank_address',\n",
       " 'phone',\n",
       " 'swift_code',\n",
       " 'company_name',\n",
       " 'marker_company_name',\n",
       " 'marker_fax',\n",
       " 'account_number',\n",
       " 'marker_bank_name',\n",
       " 'fax',\n",
       " 'tax',\n",
       " 'marker_account_number',\n",
       " 'company_address',\n",
       " 'marker_company_address',\n",
       " 'text',\n",
       " 'represented_name',\n",
       " 'bank_name',\n",
       " 'marker_phone',\n",
       " 'bank_address',\n",
       " 'marker_tax',\n",
       " 'marker_swift_code']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae0c846-a42b-42cb-9a45-0602ae9a1714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "return_entity_level_metrics = False\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b3c14e8-12f4-45f7-83fa-9fcb3f40f876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"ckpt/nonmasked/fake_data/lilt\",\n",
    "                                  num_train_epochs=100,\n",
    "                                  learning_rate=5e-5,\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  save_strategy='steps',\n",
    "                                  eval_steps=500,\n",
    "                                  save_steps=500,\n",
    "                                  save_total_limit=15,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  warmup_ratio = 0.1,\n",
    "                                  do_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e7a2f97-31a3-4c86-a6ab-59f85a603a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "  def get_train_dataloader(self):\n",
    "    return train_dataloader\n",
    "\n",
    "  def get_eval_dataloader(self, eval_dataset = None):\n",
    "    return val_dataloader\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25127d4b-851c-4ec6-8c89-9784479cdc39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='19500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  432/19500 03:15 < 2:24:23, 2.20 it/s, Epoch 2.21/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f7512-87d7-4c46-a303-a9451d4fdc24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

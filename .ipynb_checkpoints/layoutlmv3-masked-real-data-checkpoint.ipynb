{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b791ba-5675-4eca-9adc-e91e3ef2abcb",
   "metadata": {},
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ecb44-ad08-4bd1-abe7-1dae0acf05e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512559bc-07f2-424d-a77b-437cb4c49779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/data/tungtx2/tmp/transformers_hub'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e10e97-9052-42f2-923e-d990d726e392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac1f19-1c52-481f-8bc6-b33a277d4189",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92cf037-24f8-4aeb-bc14-be50f3bb0aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : 64973\n",
      "account_number : 418\n",
      "marker_account_number : 584\n",
      "swift_code : 234\n",
      "marker_swift_code : 406\n",
      "bank_name : 1492\n",
      "marker_bank_name : 425\n",
      "fax : 565\n",
      "marker_fax : 313\n",
      "phone : 962\n",
      "marker_phone : 489\n",
      "company_address : 7565\n",
      "company_name : 3915\n",
      "marker_company_name : 1351\n",
      "bank_address : 1227\n",
      "marker_bank_address : 207\n",
      "marker_company_address : 504\n",
      "represented_position : 463\n",
      "marker_represented_position : 88\n",
      "represented_name : 1075\n",
      "marker_represented_name : 611\n",
      "tax : 56\n",
      "marker_tax : 98\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'real_data/train_labeled_ocred'\n",
    "val_dir = 'real_data/val_labeled_ocred'\n",
    "\n",
    "def find_all_labels(data_dir):\n",
    "    labels = {}\n",
    "    for jp in Path(data_dir).rglob('*.json'):\n",
    "        data = json.load(open(jp))\n",
    "        for shape in data['shapes']:\n",
    "            if shape['label'] in labels:\n",
    "                labels[shape['label']] += 1\n",
    "            else:\n",
    "                labels[shape['label']] = 0\n",
    "                \n",
    "    return labels\n",
    "\n",
    "train_labels = find_all_labels(train_dir)\n",
    "val_labels = find_all_labels(val_dir)\n",
    "assert set(train_labels.keys()) == set(val_labels.keys())\n",
    "for k, v in train_labels.items():\n",
    "    print(k, ':', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ae76e4-d587-4a5a-970e-cd7c5803b103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bank_name': 0, 'text': 1, 'marker_swift_code': 2, 'marker_tax': 3, 'company_name': 4, 'marker_bank_name': 5, 'company_address': 6, 'marker_phone': 7, 'marker_account_number': 8, 'represented_position': 9, 'marker_company_name': 10, 'marker_represented_name': 11, 'phone': 12, 'tax': 13, 'bank_address': 14, 'fax': 15, 'swift_code': 16, 'marker_company_address': 17, 'account_number': 18, 'represented_name': 19, 'marker_bank_address': 20, 'marker_fax': 21, 'marker_represented_position': 22}\n",
      "{0: 'bank_name', 1: 'text', 2: 'marker_swift_code', 3: 'marker_tax', 4: 'company_name', 5: 'marker_bank_name', 6: 'company_address', 7: 'marker_phone', 8: 'marker_account_number', 9: 'represented_position', 10: 'marker_company_name', 11: 'marker_represented_name', 12: 'phone', 13: 'tax', 14: 'bank_address', 15: 'fax', 16: 'swift_code', 17: 'marker_company_address', 18: 'account_number', 19: 'represented_name', 20: 'marker_bank_address', 21: 'marker_fax', 22: 'marker_represented_position'}\n"
     ]
    }
   ],
   "source": [
    "label_list = list(set(train_labels.keys()))\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id2label = {idx: label for idx, label in enumerate(label_list)}\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a68f235-f682-43ad-a268-124b1cba628e",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "809dfe17-d67d-4298-9c5f-2800f5fbeb0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutLMv3TokenizerFast(name_or_path='microsoft/layoutlmv3-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)})\n",
      "False\n",
      "LayoutLMv3ImageProcessor {\n",
      "  \"apply_ocr\": false,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"feature_extractor_type\": \"LayoutLMv3FeatureExtractor\",\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_processor_type\": \"LayoutLMv3ImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"ocr_lang\": null,\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"tesseract_config\": \"\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3Processor, LayoutXLMTokenizerFast, LayoutLMv2FeatureExtractor\n",
    "\n",
    "# feature_extractor = LayoutLMv2FeatureExtractor(apply_ocr=False)\n",
    "# tokenizer = LayoutXLMTokenizerFast.from_pretrained('microsoft/layoutxlm-base')\n",
    "# tokenizer.only_label_first_subword = False\n",
    "# processor = LayoutXLMProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "processor = LayoutLMv3Processor.from_pretrained('microsoft/layoutlmv3-base', apply_ocr=False)\n",
    "processor.tokenizer.only_label_first_subword = False\n",
    "\n",
    "print(processor.tokenizer)\n",
    "print(processor.tokenizer.only_label_first_subword)\n",
    "print(processor.image_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d4baace-baa1-435c-9a65-e915f144a5e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import unidecode\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pdb\n",
    "import xml.etree.ElementTree as ET\n",
    "from shapely.geometry import Polygon\n",
    "import cv2\n",
    "\n",
    "\n",
    "def normalize_bbox(bbox, width, height):\n",
    "     return [\n",
    "         int(1000 * (bbox[0] / width)),\n",
    "         int(1000 * (bbox[1] / height)),\n",
    "         int(1000 * (bbox[2] / width)),\n",
    "         int(1000 * (bbox[3] / height)),\n",
    "     ]\n",
    "    \n",
    "    \n",
    "def parse_xml(xml_path):\n",
    "    root = ET.parse(xml_path).getroot()\n",
    "    objs = root.findall('object')\n",
    "    boxes, obj_names = [], []\n",
    "    for obj in objs:\n",
    "        obj_name = obj.find('name').text\n",
    "        box = obj.find('bndbox')\n",
    "        xmin = int(box.find('xmin').text)\n",
    "        ymin = int(box.find('ymin').text)\n",
    "        xmax = int(box.find('xmax').text)\n",
    "        ymax = int(box.find('ymax').text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        obj_names.append(obj_name)\n",
    "    return boxes, obj_names\n",
    "\n",
    "\n",
    "def widen_box(box, percent_x, percent_y):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        xmin -= w * percent_x\n",
    "        ymin -= h * percent_y\n",
    "        xmax += w * percent_x\n",
    "        ymax += h * percent_y\n",
    "        return (int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "\n",
    "    \n",
    "def draw_json_on_img(img, json_data):\n",
    "    labels = list(set(shape['label'] for shape in json_data['shapes']))\n",
    "    color = {}\n",
    "    for i in range(len(labels)):\n",
    "        color[labels[i]] = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
    "        \n",
    "    img = img.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_size = 0.5# Draw the text on the image\n",
    "    # font = ImageFont.truetype(font.font.family, font_size)\n",
    "    for i, shape in enumerate(json_data['shapes']):\n",
    "        polys = shape['points']\n",
    "        polys = [(int(pt[0]), int(pt[1])) for pt in polys]\n",
    "        label = shape['label']\n",
    "        draw.polygon(polys, outline=color[label], width=2)\n",
    "        # Draw the text on the image\n",
    "        img = np.array(img)\n",
    "        cv2.putText(img, shape['label'], (polys[0][0], polys[0][1]-5), font, font_size, color[label], thickness=1)\n",
    "        img = Image.fromarray(img)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "    return img\n",
    "    \n",
    "    \n",
    "def mask_image(img, boxes, json_data, widen_range_x, widen_range_y):\n",
    "    # widen block\n",
    "    if isinstance(widen_range_x, list) and isinstance(widen_range_y, list):\n",
    "        boxes = [widen_box(box, np.random.uniform(widen_range_x[0], widen_range_x[1]), np.random.uniform(widen_range_y[0], widen_range_y[1])) for box in boxes]\n",
    "    else:\n",
    "        boxes = [widen_box(box, widen_range_x, widen_range_y) for box in boxes]\n",
    "        \n",
    "    \n",
    "    ls_polys2keep = []\n",
    "    ls_area2keep = []\n",
    "    iou_threshold = 0.\n",
    "    for box_idx, box in enumerate(boxes):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        box_pts = [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]\n",
    "        p_box = Polygon(box_pts)\n",
    "        for shape_idx, shape in enumerate(json_data['shapes']):\n",
    "            if shape_idx in ls_polys2keep:\n",
    "                continue\n",
    "            pts = shape['points']\n",
    "            p_shape = Polygon(pts)\n",
    "            intersect_area = p_box.intersection(p_shape).area\n",
    "            if intersect_area / p_shape.area > iou_threshold:\n",
    "                ls_polys2keep.append(shape_idx)\n",
    "                pts = [coord for pt in pts for coord in pt]\n",
    "                poly_xmin = min(pts[::2])\n",
    "                poly_ymin = min(pts[1::2])\n",
    "                poly_xmax = max(pts[::2])\n",
    "                poly_ymax = max(pts[1::2])\n",
    "                ls_area2keep.append((poly_xmin, poly_ymin, poly_xmax, poly_ymax))\n",
    "\n",
    "    # mask white all area of image that is not in block\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        xmin = max(0, xmin)\n",
    "        ymin = max(0, ymin)\n",
    "        xmax = min(img.shape[1], xmax)\n",
    "        ymax = min(img.shape[0], ymax)\n",
    "        mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "    for area2keep in ls_area2keep:\n",
    "        xmin, ymin, xmax, ymax = area2keep\n",
    "        xmin = int(max(0, xmin))\n",
    "        ymin = int(max(0, ymin))\n",
    "        xmax = int(min(img.shape[1], xmax))\n",
    "        ymax = int(min(img.shape[0], ymax))\n",
    "        mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "    # mask white\n",
    "    img[mask == 0] = 255\n",
    "\n",
    "    # delete all poly that is not in block\n",
    "    ls_idx2del = [idx for idx, shape in enumerate(json_data['shapes']) if idx not in ls_polys2keep]\n",
    "    for idx in sorted(ls_idx2del, reverse=True):\n",
    "        del json_data['shapes'][idx]\n",
    "\n",
    "    return img, json_data\n",
    "        \n",
    "\n",
    "def gen_annotation_for_img(img_fp, xml_fp, json_fp, masked=False, widen_range_x=[0.1, 0.2], widen_range_y=[0.1, 0.25]):\n",
    "    img = Image.open(img_fp).convert(\"RGB\")\n",
    "    boxes, obj_names = parse_xml(xml_fp)\n",
    "    json_data = json.load(open(json_fp))\n",
    "    \n",
    "    if masked:\n",
    "        img, json_data = mask_image(np.array(img), boxes=boxes, json_data=json_data, widen_range_x=widen_range_x, widen_range_y=widen_range_y)\n",
    "        img = Image.fromarray(img)\n",
    "        # pdb.set_trace()\n",
    "        \n",
    "    words, boxes, labels = [], [], []\n",
    "    img_h, img_w = json_data['imageHeight'], json_data['imageWidth']\n",
    "    for i, shape in enumerate(json_data['shapes']):\n",
    "      words.append(unidecode.unidecode(shape['text'].lower()))\n",
    "      # words.append(shape['text'].lower())\n",
    "      labels.append(shape['label'])\n",
    "      pts = [coord for pt in shape['points'] for coord in pt]\n",
    "      xmin = min(pts[0::2])\n",
    "      xmax = max(pts[0::2])\n",
    "      ymin = min(pts[1::2])\n",
    "      ymax = max(pts[1::2])\n",
    "\n",
    "      xmin = max(xmin, 0)\n",
    "      ymin = max(ymin, 0)\n",
    "      xmax = min(img_w, xmax)\n",
    "      ymax = min(img_h, ymax)\n",
    "\n",
    "      boxes.append(normalize_bbox((xmin, ymin, xmax, ymax), img_w, img_h))\n",
    "\n",
    "    return img, words, boxes, labels\n",
    "\n",
    "\n",
    "class CORDDataset(Dataset):\n",
    "    \"\"\"CORD dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, file_paths, processor=None, max_length=512, masked=False, widen_range_x=[0.1, 0.2], widen_range_y=[0.1, 0.25]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotations (List[List]): List of lists containing the word-level annotations (words, labels, boxes).\n",
    "            image_dir (string): Directory with all the document images.\n",
    "            processor (LayoutLMv2Processor): Processor to prepare the text + image.\n",
    "        \"\"\"\n",
    "        self.ls_img_fp, self.ls_xml_fp, self.ls_json_fp = file_paths\n",
    "        assert len(self.ls_img_fp) == len(self.ls_json_fp) == len(self.ls_xml_fp)\n",
    "        self.processor = processor\n",
    "        self.masked = masked\n",
    "        self.widen_range_x = widen_range_x\n",
    "        self.widen_range_y = widen_range_y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ls_img_fp)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # first, take an image\n",
    "        img_fp = self.ls_img_fp[index]\n",
    "        xml_fp = self.ls_xml_fp[index]\n",
    "        json_fp = self.ls_json_fp[index]\n",
    "        \n",
    "        img, words, boxes, text_labels = gen_annotation_for_img(img_fp, xml_fp, json_fp, masked=self.masked, widen_range_x=self.widen_range_x, widen_range_y=self.widen_range_y)\n",
    "        idx_labels = [label2id[label] for label in text_labels]\n",
    "\n",
    "        encoded_inputs = processor(img, words, boxes=boxes, word_labels=idx_labels, truncation=True, stride =128, \n",
    "                            padding=\"max_length\", max_length=512, return_overflowing_tokens=True, return_offsets_mapping=True, return_tensors=\"pt\")  \n",
    "        \n",
    "        # print(encoded_inputs.keys())\n",
    "        overflow_to_sample_mapping = encoded_inputs.pop('overflow_to_sample_mapping')\n",
    "        offset_mapping = encoded_inputs.pop('offset_mapping')\n",
    "        # print('overflow_to_sample_mapping: ', overflow_to_sample_mapping)\n",
    "        # print('offset_mapping: ', offset_mapping)\n",
    "\n",
    "        # remove batch dimension\n",
    "        idx = np.random.randint(0, len(encoded_inputs['pixel_values']))\n",
    "        for k, v in encoded_inputs.items():\n",
    "            encoded_inputs[k] = v[idx]\n",
    "      \n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9043099-deab-4970-bc3c-346f2879aa34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(data_dir):\n",
    "    ls_img_fp, ls_xml_fp, ls_json_fp = [], [], []\n",
    "    for img_fp in Path(data_dir).rglob('*.jpg'):\n",
    "        json_fp = img_fp.with_suffix('.json')\n",
    "        xml_fp = img_fp.with_suffix('.xml')\n",
    "        \n",
    "        ls_img_fp.append(str(img_fp))\n",
    "        ls_xml_fp.append(str(xml_fp))\n",
    "        ls_json_fp.append(str(json_fp))\n",
    "    \n",
    "    return ls_img_fp, ls_xml_fp, ls_json_fp\n",
    "\n",
    "\n",
    "train_file_paths = get_file_paths(train_dir)\n",
    "val_file_paths = get_file_paths(val_dir)\n",
    "\n",
    "widen_range_x = [0.1, 0.2]\n",
    "widen_range_y = [0.1, 0.25]\n",
    "train_dataset = CORDDataset(file_paths=train_file_paths, processor=processor, masked=True, \n",
    "                            widen_range_x=widen_range_x, widen_range_y=widen_range_y)\n",
    "val_dataset = CORDDataset(file_paths=val_file_paths, processor=processor, masked=True, \n",
    "                          widen_range_x=0.1, widen_range_y=0.15)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c0b49b-27b0-493c-906e-44497b302a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([512])\n",
      "attention_mask torch.Size([512])\n",
      "bbox torch.Size([512, 4])\n",
      "labels torch.Size([512])\n",
      "pixel_values torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "encoding = val_dataset[9]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a6c7314-9dff-4fa9-9b8a-bd33ac09e081",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "(' mentioned', 'text', tensor([616, 353, 680, 362]))\n",
      "('.', 'text', tensor([616, 353, 680, 362]))\n",
      "(' here', 'text', tensor([555, 353, 612, 362]))\n",
      "('und', 'text', tensor([555, 353, 612, 362]))\n",
      "('e', 'text', tensor([555, 353, 612, 362]))\n",
      "(' conditions', 'text', tensor([496, 353, 551, 362]))\n",
      "(\" '\", 'text', tensor([332, 353, 369, 362]))\n",
      "('article', 'text', tensor([332, 353, 369, 362]))\n",
      "(' and', 'text', tensor([468, 350, 493, 364]))\n",
      "(' terms', 'text', tensor([434, 350, 468, 364]))\n",
      "(' the', 'text', tensor([413, 352, 432, 363]))\n",
      "(' with', 'text', tensor([386, 350, 413, 364]))\n",
      "(' r', 'text', tensor([372, 352, 386, 364]))\n",
      "(\"'\", 'text', tensor([372, 352, 386, 364]))\n",
      "(' at', 'text', tensor([315, 352, 328, 364]))\n",
      "(' items', 'text', tensor([281, 350, 313, 364]))\n",
      "(' of', 'text', tensor([263, 352, 277, 363]))\n",
      "(' sales', 'text', tensor([229, 350, 262, 364]))\n",
      "(' the', 'text', tensor([207, 350, 230, 364]))\n",
      "(' agreed', 'text', tensor([149, 350, 189, 363]))\n",
      "(' on', 'text', tensor([191, 350, 207, 363]))\n",
      "(' have', 'text', tensor([116, 349, 148, 364]))\n",
      "(' parties', 'text', tensor([ 75, 349, 116, 364]))\n",
      "(' both', 'text', tensor([ 44, 349,  74, 363]))\n",
      "(' v', 'bank_address', tensor([418, 327, 463, 335]))\n",
      "('iet', 'bank_address', tensor([418, 327, 463, 335]))\n",
      "('nan', 'bank_address', tensor([418, 327, 463, 335]))\n",
      "(' bank', 'bank_name', tensor([284, 326, 317, 338]))\n",
      "(' commer', 'bank_name', tensor([213, 327, 277, 335]))\n",
      "('cia', 'bank_name', tensor([213, 327, 277, 335]))\n",
      "(' city', 'bank_address', tensor([386, 324, 416, 338]))\n",
      "(',', 'bank_address', tensor([386, 324, 416, 338]))\n",
      "(' min', 'bank_address', tensor([355, 324, 388, 338]))\n",
      "('h', 'bank_address', tensor([355, 324, 388, 338]))\n",
      "(' chi', 'bank_address', tensor([333, 324, 357, 340]))\n",
      "(' as', 'bank_name', tensor([182, 324, 210, 338]))\n",
      "('ia', 'bank_name', tensor([182, 324, 210, 338]))\n",
      "(' at', 'marker_bank_name', tensor([165, 326, 178, 338]))\n",
      "(' ho', 'bank_address', tensor([313, 324, 333, 338]))\n",
      "(' 19', 'account_number', tensor([218, 313, 262, 322]))\n",
      "('199', 'account_number', tensor([218, 313, 262, 322]))\n",
      "('66', 'account_number', tensor([218, 313, 262, 322]))\n",
      "(' no', 'marker_account_number', tensor([186, 309, 215, 324]))\n",
      "('.:', 'marker_account_number', tensor([186, 309, 215, 324]))\n",
      "(' a', 'marker_account_number', tensor([165, 309, 188, 324]))\n",
      "('/', 'marker_account_number', tensor([165, 309, 188, 324]))\n",
      "('c', 'marker_account_number', tensor([165, 309, 188, 324]))\n",
      "(' -', 'represented_position', tensor([401, 298, 457, 310]))\n",
      "('director', 'represented_position', tensor([401, 298, 457, 310]))\n",
      "(' qu', 'represented_name', tensor([360, 298, 401, 310]))\n",
      "('ang', 'represented_name', tensor([360, 298, 401, 310]))\n",
      "(' n', 'represented_name', tensor([279, 298, 326, 310]))\n",
      "('guyen', 'represented_name', tensor([279, 298, 326, 310]))\n",
      "(' represent', 'marker_represented_name', tensor([167, 300, 238, 308]))\n",
      "('er', 'marker_represented_name', tensor([167, 300, 238, 308]))\n",
      "(' x', 'represented_name', tensor([326, 296, 360, 310]))\n",
      "('uan', 'represented_name', tensor([326, 296, 360, 310]))\n",
      "(' m', 'represented_name', tensor([257, 296, 279, 312]))\n",
      "('r', 'represented_name', tensor([257, 296, 279, 312]))\n",
      "('.', 'represented_name', tensor([257, 296, 279, 312]))\n",
      "(' by', 'marker_represented_name', tensor([241, 298, 257, 310]))\n",
      "(' 37', 'phone', tensor([221, 284, 271, 296]))\n",
      "('28', 'phone', tensor([221, 284, 271, 296]))\n",
      "('288', 'phone', tensor([221, 284, 271, 296]))\n",
      "(' 1', 'phone', tensor([204, 283, 224, 298]))\n",
      "(' 84', 'phone', tensor([189, 282, 210, 298]))\n",
      "('-', 'phone', tensor([189, 282, 210, 298]))\n",
      "(' tel', 'marker_phone', tensor([162, 281, 193, 300]))\n",
      "(':', 'marker_phone', tensor([162, 281, 193, 300]))\n",
      "(' n', 'company_address', tensor([372, 270, 407, 284]))\n",
      "('am', 'company_address', tensor([372, 270, 407, 284]))\n",
      "('.', 'company_address', tensor([372, 270, 407, 284]))\n",
      "(' min', 'company_address', tensor([288, 270, 320, 283]))\n",
      "('h', 'company_address', tensor([288, 270, 320, 283]))\n",
      "(' v', 'company_address', tensor([346, 269, 372, 284]))\n",
      "('iet', 'company_address', tensor([346, 269, 372, 284]))\n",
      "(' city', 'company_address', tensor([318, 269, 347, 284]))\n",
      "(',', 'company_address', tensor([318, 269, 347, 284]))\n",
      "(' chi', 'company_address', tensor([265, 269, 288, 284]))\n",
      "(' ho', 'company_address', tensor([244, 269, 266, 284]))\n",
      "(' city', 'company_address', tensor([218, 269, 244, 284]))\n",
      "(',', 'company_address', tensor([218, 269, 244, 284]))\n",
      "(' d', 'company_address', tensor([189, 269, 215, 283]))\n",
      "('uc', 'company_address', tensor([189, 269, 215, 283]))\n",
      "(' th', 'company_address', tensor([166, 269, 193, 283]))\n",
      "('u', 'company_address', tensor([166, 269, 193, 283]))\n",
      "(' long', 'company_address', tensor([522, 259, 551, 269]))\n",
      "(' ph', 'company_address', tensor([484, 258, 522, 270]))\n",
      "('u', 'company_address', tensor([484, 258, 522, 270]))\n",
      "('oc', 'company_address', tensor([484, 258, 522, 270]))\n",
      "(' ch', 'company_address', tensor([346, 259, 443, 268]))\n",
      "('ie', 'company_address', tensor([346, 259, 443, 268]))\n",
      "('c', 'company_address', tensor([346, 259, 443, 268]))\n",
      "('.', 'company_address', tensor([346, 259, 443, 268]))\n",
      "('resident', 'company_address', tensor([346, 259, 443, 268]))\n",
      "('ia', 'company_address', tensor([346, 259, 443, 268]))\n",
      "(' ward', 'company_address', tensor([565, 256, 599, 270]))\n",
      "(',', 'company_address', tensor([565, 256, 599, 270]))\n",
      "(' area', 'company_address', tensor([448, 256, 484, 270]))\n",
      "(',', 'company_address', tensor([448, 256, 484, 270]))\n",
      "(' r', 'company_address', tensor([312, 256, 343, 270]))\n",
      "('ach', 'company_address', tensor([312, 256, 343, 270]))\n",
      "(' a', 'company_address', tensor([552, 256, 565, 270]))\n",
      "(' b', 'company_address', tensor([284, 255, 310, 270]))\n",
      "('ac', 'company_address', tensor([284, 255, 310, 270]))\n",
      "(' street', 'company_address', tensor([240, 255, 283, 272]))\n",
      "('.', 'company_address', tensor([240, 255, 283, 272]))\n",
      "(' 410', 'company_address', tensor([208, 255, 240, 270]))\n",
      "('c', 'company_address', tensor([208, 255, 240, 270]))\n",
      "(' l', 'company_name', tensor([423, 243, 463, 256]))\n",
      "('td', 'company_name', tensor([423, 243, 463, 256]))\n",
      "('.)', 'company_name', tensor([423, 243, 463, 256]))\n",
      "(' co', 'company_name', tensor([394, 243, 423, 256]))\n",
      "('.,', 'company_name', tensor([394, 243, 423, 256]))\n",
      "(' (', 'company_name', tensor([346, 243, 393, 256]))\n",
      "('med', 'company_name', tensor([346, 243, 393, 256]))\n",
      "('in', 'company_name', tensor([346, 243, 393, 256]))\n",
      "(' limited', 'company_name', tensor([290, 243, 344, 255]))\n",
      "(' company', 'company_name', tensor([224, 243, 290, 255]))\n",
      "(' din', 'company_name', tensor([189, 242, 222, 256]))\n",
      "('h', 'company_name', tensor([189, 242, 222, 256]))\n",
      "(' buyer', 'marker_company_name', tensor([ 77, 242, 126, 255]))\n",
      "(':', 'marker_company_name', tensor([ 77, 242, 126, 255]))\n",
      "('.', 'text', tensor([580, 243, 588, 252]))\n",
      "(',', 'text', tensor([580, 243, 588, 252]))\n",
      "(' the', 'marker_company_name', tensor([ 47, 241,  76, 256]))\n",
      "(' b', 'represented_name', tensor([366, 230, 421, 243]))\n",
      "('ais', 'represented_name', tensor([366, 230, 421, 243]))\n",
      "('heng', 'represented_name', tensor([366, 230, 421, 243]))\n",
      "(' w', 'represented_name', tensor([335, 229, 364, 243]))\n",
      "('en', 'represented_name', tensor([335, 229, 364, 243]))\n",
      "(' represented', 'marker_represented_name', tensor([171, 229, 243, 242]))\n",
      "(' m', 'represented_name', tensor([317, 229, 333, 243]))\n",
      "('r', 'represented_name', tensor([317, 229, 333, 243]))\n",
      "(' ;', 'text', tensor([306, 230, 313, 241]))\n",
      "(' by', 'marker_represented_name', tensor([246, 229, 260, 243]))\n",
      "(' +', 'fax', tensor([336, 218, 434, 228]))\n",
      "('86', 'fax', tensor([336, 218, 434, 228]))\n",
      "('-', 'fax', tensor([336, 218, 434, 228]))\n",
      "('755', 'fax', tensor([336, 218, 434, 228]))\n",
      "('-', 'fax', tensor([336, 218, 434, 228]))\n",
      "('28', 'fax', tensor([336, 218, 434, 228]))\n",
      "('44', 'fax', tensor([336, 218, 434, 228]))\n",
      "('379', 'fax', tensor([336, 218, 434, 228]))\n",
      "(' fax', 'marker_fax', tensor([304, 215, 333, 229]))\n",
      "(':', 'marker_fax', tensor([304, 215, 333, 229]))\n",
      "(' +', 'phone', tensor([193, 215, 291, 228]))\n",
      "('86', 'phone', tensor([193, 215, 291, 228]))\n",
      "('-', 'phone', tensor([193, 215, 291, 228]))\n",
      "('755', 'phone', tensor([193, 215, 291, 228]))\n",
      "('-', 'phone', tensor([193, 215, 291, 228]))\n",
      "('89', 'phone', tensor([193, 215, 291, 228]))\n",
      "('340', 'phone', tensor([193, 215, 291, 228]))\n",
      "('96', 'phone', tensor([193, 215, 291, 228]))\n",
      "(' tel', 'marker_phone', tensor([166, 214, 191, 229]))\n",
      "(':', 'marker_phone', tensor([166, 214, 191, 229]))\n",
      "(' 5', 'company_address', tensor([329, 203, 377, 215]))\n",
      "('18', 'company_address', tensor([329, 203, 377, 215]))\n",
      "('109', 'company_address', tensor([329, 203, 377, 215]))\n",
      "('.', 'company_address', tensor([329, 203, 377, 215]))\n",
      "(' ch', 'company_address', tensor([293, 202, 329, 215]))\n",
      "('ina', 'company_address', tensor([293, 202, 329, 215]))\n",
      "(' in', 'company_address', tensor([265, 202, 291, 215]))\n",
      "('ce', 'company_address', tensor([265, 202, 291, 215]))\n",
      "(',', 'company_address', tensor([265, 202, 291, 215]))\n",
      "(' prov', 'company_address', tensor([237, 202, 268, 215]))\n",
      "('i', 'company_address', tensor([237, 202, 268, 215]))\n",
      "(' gu', 'company_address', tensor([167, 202, 233, 215]))\n",
      "('ang', 'company_address', tensor([167, 202, 233, 215]))\n",
      "('d', 'company_address', tensor([167, 202, 233, 215]))\n",
      "('ong', 'company_address', tensor([167, 202, 233, 215]))\n",
      "(' she', 'company_address', tensor([569, 187, 632, 202]))\n",
      "('nz', 'company_address', tensor([569, 187, 632, 202]))\n",
      "('hen', 'company_address', tensor([569, 187, 632, 202]))\n",
      "(',', 'company_address', tensor([569, 187, 632, 202]))\n",
      "(' district', 'company_address', tensor([524, 188, 566, 202]))\n",
      "(',', 'company_address', tensor([524, 188, 566, 202]))\n",
      "(' new', 'company_address', tensor([493, 188, 522, 202]))\n",
      "(' l', 'company_address', tensor([443, 188, 492, 202]))\n",
      "('ongh', 'company_address', tensor([443, 188, 492, 202]))\n",
      "('ua', 'company_address', tensor([443, 188, 492, 202]))\n",
      "(' road', 'company_address', tensor([404, 188, 440, 202]))\n",
      "(',', 'company_address', tensor([404, 188, 440, 202]))\n",
      "(' d', 'company_address', tensor([307, 188, 338, 202]))\n",
      "('ong', 'company_address', tensor([307, 188, 338, 202]))\n",
      "(' building', 'company_address', tensor([259, 188, 304, 201]))\n",
      "(' no', 'company_address', tensor([374, 187, 405, 202]))\n",
      "('.', 'company_address', tensor([374, 187, 405, 202]))\n",
      "('1', 'company_address', tensor([374, 187, 405, 202]))\n",
      "(' h', 'company_address', tensor([339, 187, 374, 201]))\n",
      "('uan', 'company_address', tensor([339, 187, 374, 201]))\n",
      "(' x', 'company_address', tensor([230, 187, 257, 202]))\n",
      "('uri', 'company_address', tensor([230, 187, 257, 202]))\n",
      "(' technology', 'company_name', tensor([284, 173, 371, 186]))\n",
      "(' l', 'company_name', tensor([404, 172, 432, 187]))\n",
      "('td', 'company_name', tensor([404, 172, 432, 187]))\n",
      "(' co', 'company_name', tensor([374, 172, 404, 187]))\n",
      "('.,', 'company_name', tensor([374, 172, 404, 187]))\n",
      "(' f', 'company_name', tensor([238, 170, 281, 188]))\n",
      "('ais', 'company_name', tensor([238, 170, 281, 188]))\n",
      "('r', 'company_name', tensor([238, 170, 281, 188]))\n",
      "(' enz', 'company_name', tensor([183, 170, 238, 188]))\n",
      "('hen', 'company_name', tensor([183, 170, 238, 188]))\n",
      "(' seller', 'marker_company_name', tensor([ 77, 172, 131, 186]))\n",
      "(':', 'marker_company_name', tensor([ 77, 172, 131, 186]))\n",
      "(' the', 'marker_company_name', tensor([ 47, 172,  77, 186]))\n",
      "(\" '\", 'text', tensor([270, 127, 279, 170]))\n",
      "('</s>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "ls_token = [processor.tokenizer.decode(input_id) for input_id in encoding['input_ids']]\n",
    "ls_label = [id2label[int(label_id)] if label_id != -100 else 'SPECIAL' for label_id in encoding['labels'] ]\n",
    "ls_bb = list(encoding['bbox'])\n",
    "for item in zip(ls_token, ls_label, ls_bb):\n",
    "  print(item)\n",
    "  # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2606efa9-5cfb-419d-afce-b7ea5eb5c247",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([4, 512])\n",
      "attention_mask torch.Size([4, 512])\n",
      "bbox torch.Size([4, 512, 4])\n",
      "labels torch.Size([4, 512])\n",
      "pixel_values torch.Size([4, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "for item in train_dataloader:\n",
    "  for k, v in item.items():\n",
    "    print(k, v.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b6471-d0c8-4f2d-9334-5805f07b345e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6abc5a6-379c-4bce-9fe5-8c8ed2fdff28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutLMv3ForTokenClassification(\n",
      "  (layoutlmv3): LayoutLMv3Model(\n",
      "    (embeddings): LayoutLMv3TextEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (x_position_embeddings): Embedding(1024, 128)\n",
      "      (y_position_embeddings): Embedding(1024, 128)\n",
      "      (h_position_embeddings): Embedding(1024, 128)\n",
      "      (w_position_embeddings): Embedding(1024, 128)\n",
      "    )\n",
      "    (patch_embed): LayoutLMv3PatchEmbeddings(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (encoder): LayoutLMv3Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_pos_bias): Linear(in_features=32, out_features=12, bias=False)\n",
      "      (rel_pos_x_bias): Linear(in_features=64, out_features=12, bias=False)\n",
      "      (rel_pos_y_bias): Linear(in_features=64, out_features=12, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): LayoutLMv3ClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=21, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3ForTokenClassification, AdamW\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained('ckpt/masked/fake_data/layoutlmv3/checkpoint-7500')\n",
    "# model = LayoutLMv3ForTokenClassification.from_pretrained('microsoft/layoutlmv3-base', id2label=id2label)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed551c-7cb4-4c08-82cd-bc41ccaeb778",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "434f0ee4-1eb8-45b5-805e-7138738991c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutLMv3ForTokenClassification(\n",
      "  (layoutlmv3): LayoutLMv3Model(\n",
      "    (embeddings): LayoutLMv3TextEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (x_position_embeddings): Embedding(1024, 128)\n",
      "      (y_position_embeddings): Embedding(1024, 128)\n",
      "      (h_position_embeddings): Embedding(1024, 128)\n",
      "      (w_position_embeddings): Embedding(1024, 128)\n",
      "    )\n",
      "    (patch_embed): LayoutLMv3PatchEmbeddings(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (encoder): LayoutLMv3Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): LayoutLMv3Layer(\n",
      "          (attention): LayoutLMv3Attention(\n",
      "            (self): LayoutLMv3SelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): LayoutLMv3SelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): LayoutLMv3Intermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): LayoutLMv3Output(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_pos_bias): Linear(in_features=32, out_features=12, bias=False)\n",
      "      (rel_pos_x_bias): Linear(in_features=64, out_features=12, bias=False)\n",
      "      (rel_pos_y_bias): Linear(in_features=64, out_features=12, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): LayoutLMv3ClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=23, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "LayoutLMv3Config {\n",
      "  \"_name_or_path\": \"ckpt/masked/fake_data/layoutlmv3/checkpoint-7500\",\n",
      "  \"architectures\": [\n",
      "    \"LayoutLMv3ForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"coordinate_size\": 128,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"has_relative_attention_bias\": true,\n",
      "  \"has_spatial_attention_bias\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"bank_name\",\n",
      "    \"1\": \"text\",\n",
      "    \"2\": \"marker_swift_code\",\n",
      "    \"3\": \"marker_tax\",\n",
      "    \"4\": \"company_name\",\n",
      "    \"5\": \"marker_bank_name\",\n",
      "    \"6\": \"company_address\",\n",
      "    \"7\": \"marker_phone\",\n",
      "    \"8\": \"marker_account_number\",\n",
      "    \"9\": \"represented_position\",\n",
      "    \"10\": \"marker_company_name\",\n",
      "    \"11\": \"marker_represented_name\",\n",
      "    \"12\": \"phone\",\n",
      "    \"13\": \"tax\",\n",
      "    \"14\": \"bank_address\",\n",
      "    \"15\": \"fax\",\n",
      "    \"16\": \"swift_code\",\n",
      "    \"17\": \"marker_company_address\",\n",
      "    \"18\": \"account_number\",\n",
      "    \"19\": \"represented_name\",\n",
      "    \"20\": \"marker_bank_address\",\n",
      "    \"21\": \"marker_fax\",\n",
      "    \"22\": \"marker_represented_position\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"input_size\": 224,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"account_number\": 18,\n",
      "    \"bank_address\": 14,\n",
      "    \"bank_name\": 0,\n",
      "    \"company_address\": 6,\n",
      "    \"company_name\": 4,\n",
      "    \"fax\": 15,\n",
      "    \"marker_account_number\": 8,\n",
      "    \"marker_bank_address\": 20,\n",
      "    \"marker_bank_name\": 5,\n",
      "    \"marker_company_address\": 17,\n",
      "    \"marker_company_name\": 10,\n",
      "    \"marker_fax\": 21,\n",
      "    \"marker_phone\": 7,\n",
      "    \"marker_represented_name\": 11,\n",
      "    \"marker_represented_position\": 22,\n",
      "    \"marker_swift_code\": 2,\n",
      "    \"marker_tax\": 3,\n",
      "    \"phone\": 12,\n",
      "    \"represented_name\": 19,\n",
      "    \"represented_position\": 9,\n",
      "    \"swift_code\": 16,\n",
      "    \"tax\": 13,\n",
      "    \"text\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_2d_position_embeddings\": 1024,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"max_rel_2d_pos\": 256,\n",
      "  \"max_rel_pos\": 128,\n",
      "  \"model_type\": \"layoutlmv3\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"patch_size\": 16,\n",
      "  \"rel_2d_pos_bins\": 64,\n",
      "  \"rel_pos_bins\": 32,\n",
      "  \"second_input_size\": 112,\n",
      "  \"shape_size\": 128,\n",
      "  \"text_embed\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"visual_embed\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model.classifier.out_proj = nn.Linear(in_features=768, out_features=len(label_list), bias=True)\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "model.num_labels = len(label_list)\n",
    "\n",
    "print(model)\n",
    "print()\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603acfe9-04aa-4ce7-9056-25b4e2875d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c1f3b-677b-4159-9939-c503ba2c3291",
   "metadata": {},
   "source": [
    "# Hugging Face Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481cef0-a46a-4ecc-aefc-79add05c9f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60fabfcb-027c-4d75-bb8a-38863393dbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "return_entity_level_metrics = False\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0f982d2-4644-4019-ba6e-727287173ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"ckpt/masked/real_data/layoutlmv3_pretrained_fake_data\",\n",
    "                                  num_train_epochs=100,\n",
    "                                  learning_rate=5e-5,\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  save_strategy='steps',\n",
    "                                  eval_steps=200,\n",
    "                                  save_steps=200,\n",
    "                                  save_total_limit=15,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  warmup_ratio = 0.1,\n",
    "                                  do_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7e31e85-72a2-4bb5-bde7-66bae03658e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "  def get_train_dataloader(self):\n",
    "    return train_dataloader\n",
    "\n",
    "  def get_eval_dataloader(self, eval_dataset = None):\n",
    "    return val_dataloader\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "705adda3-0d05-4977-b7dc-5398879f682f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/modeling_utils.py:831: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='71' max='7600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  71/7600 01:10 < 2:09:01, 0.97 it/s, Epoch 0.92/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22981/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1638\u001b[0m         )\n\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1872\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrng_to_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22981/2391827017.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mjson_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls_json_fp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_annotation_for_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxml_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiden_range_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwiden_range_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiden_range_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwiden_range_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0midx_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22981/2391827017.py\u001b[0m in \u001b[0;36mgen_annotation_for_img\u001b[0;34m(img_fp, xml_fp, json_fp, masked, widen_range_x, widen_range_y)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiden_range_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwiden_range_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiden_range_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwiden_range_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22981/2391827017.py\u001b[0m in \u001b[0;36mmask_image\u001b[0;34m(img, boxes, json_data, widen_range_x, widen_range_y)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# mask white\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# delete all poly that is not in block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7796fb4-5195-4c63-81f1-01600d8ed2be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30112bf4-da21-4386-b5f5-c66c1a41ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913e7db-92bd-4b25-81e1-af18b5de73fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

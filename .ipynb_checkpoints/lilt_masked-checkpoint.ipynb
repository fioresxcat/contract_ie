{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2a2b3f-3b2b-4bd9-a53e-00196fad3700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/huggingface\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b4b237-4b8a-43a9-9811-190fc590a7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 25 16:10:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:00:06.0 Off |                  N/A |\n",
      "| 27%   38C    P8    19W / 250W |   8997MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:00:0A.0 Off |                  N/A |\n",
      "| 27%   39C    P8    22W / 250W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     11694      C   ...nnh8/torch_env/bin/python     1815MiB |\n",
      "|    0   N/A  N/A     24138      C   ...tx2/env_ocr/bin/python3.7     7179MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c32c26-a6bc-4afd-8cba-43c9f2fa3f02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/data/tungtx2/tmp/transformers_hub'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9775c3-2d3f-4bbe-92f4-61be2e0a0fb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from os import listdir\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import unidecode\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pdb\n",
    "import xml.etree.ElementTree as ET\n",
    "from shapely.geometry import Polygon\n",
    "import cv2\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70781143-2084-43d7-9757-f9f6acb52dd8",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1387f7b9-e798-4e2a-9929-3b498fb3dc31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swift_code : 1205\n",
      "marker_swift_code : 2482\n",
      "bank_address : 6476\n",
      "marker_bank_address : 759\n",
      "bank_name : 7245\n",
      "marker_bank_name : 2218\n",
      "account_number : 1943\n",
      "marker_account_number : 2954\n",
      "marker_company_name : 3598\n",
      "text : 104778\n",
      "tax : 1316\n",
      "marker_tax : 1919\n",
      "phone : 1934\n",
      "marker_phone : 1923\n",
      "represented_name : 5742\n",
      "marker_represented_name : 1766\n",
      "marker_fax : 1888\n",
      "fax : 1931\n",
      "company_address : 9146\n",
      "marker_company_address : 1095\n",
      "company_name : 9426\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'fake_data_24032023/non_masked/train'\n",
    "val_dir = 'fake_data_24032023/non_masked/val'\n",
    "\n",
    "def find_all_labels(data_dir):\n",
    "    labels = {}\n",
    "    for jp in Path(data_dir).rglob('*.json'):\n",
    "        data = json.load(open(jp))\n",
    "        for shape in data['shapes']:\n",
    "            if shape['label'] in labels:\n",
    "                labels[shape['label']] += 1\n",
    "            else:\n",
    "                labels[shape['label']] = 0\n",
    "                \n",
    "    return labels\n",
    "\n",
    "train_labels = find_all_labels(train_dir)\n",
    "val_labels = find_all_labels(val_dir)\n",
    "assert set(train_labels.keys()) == set(val_labels.keys())\n",
    "for k, v in train_labels.items():\n",
    "    print(k, ':', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7c0ca9f-184c-4657-a1bd-54e28767c841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tax': 0, 'marker_phone': 1, 'marker_company_address': 2, 'company_name': 3, 'bank_name': 4, 'marker_company_name': 5, 'company_address': 6, 'marker_account_number': 7, 'marker_bank_address': 8, 'marker_tax': 9, 'marker_swift_code': 10, 'fax': 11, 'bank_address': 12, 'account_number': 13, 'text': 14, 'marker_represented_name': 15, 'swift_code': 16, 'marker_fax': 17, 'represented_name': 18, 'marker_bank_name': 19, 'phone': 20}\n",
      "{0: 'tax', 1: 'marker_phone', 2: 'marker_company_address', 3: 'company_name', 4: 'bank_name', 5: 'marker_company_name', 6: 'company_address', 7: 'marker_account_number', 8: 'marker_bank_address', 9: 'marker_tax', 10: 'marker_swift_code', 11: 'fax', 12: 'bank_address', 13: 'account_number', 14: 'text', 15: 'marker_represented_name', 16: 'swift_code', 17: 'marker_fax', 18: 'represented_name', 19: 'marker_bank_name', 20: 'phone'}\n"
     ]
    }
   ],
   "source": [
    "label_list = list(set(train_labels.keys()))\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id2label = {idx: label for idx, label in enumerate(label_list)}\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8cd27-63ca-460a-8b23-4ea55a874b67",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2f33a90-0aef-4816-9ebf-51c77e61663f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutXLMTokenizerFast(name_or_path='SCUT-DLVCLab/lilt-infoxlm-base', vocab_size=250002, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "LayoutLMv2FeatureExtractor {\n",
      "  \"apply_ocr\": false,\n",
      "  \"do_resize\": true,\n",
      "  \"image_processor_type\": \"LayoutLMv2FeatureExtractor\",\n",
      "  \"ocr_lang\": null,\n",
      "  \"resample\": 2,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"tesseract_config\": \"\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutXLMTokenizerFast, LayoutLMv2FeatureExtractor, LayoutXLMProcessor\n",
    "\n",
    "feature_extractor = LayoutLMv2FeatureExtractor(apply_ocr=False)\n",
    "tokenizer = LayoutXLMTokenizerFast.from_pretrained('SCUT-DLVCLab/lilt-infoxlm-base')\n",
    "tokenizer.only_label_first_subword = False\n",
    "processor = LayoutXLMProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "print(processor.tokenizer)\n",
    "print(processor.feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "630a7555-912e-4d61-a065-ba5e059f55ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_bbox(bbox, width, height):\n",
    "     return [\n",
    "         int(1000 * (bbox[0] / width)),\n",
    "         int(1000 * (bbox[1] / height)),\n",
    "         int(1000 * (bbox[2] / width)),\n",
    "         int(1000 * (bbox[3] / height)),\n",
    "     ]\n",
    "    \n",
    "    \n",
    "def parse_xml(xml_path):\n",
    "    root = ET.parse(xml_path).getroot()\n",
    "    objs = root.findall('object')\n",
    "    boxes, obj_names = [], []\n",
    "    for obj in objs:\n",
    "        obj_name = obj.find('name').text\n",
    "        box = obj.find('bndbox')\n",
    "        xmin = int(box.find('xmin').text)\n",
    "        ymin = int(box.find('ymin').text)\n",
    "        xmax = int(box.find('xmax').text)\n",
    "        ymax = int(box.find('ymax').text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        obj_names.append(obj_name)\n",
    "    return boxes, obj_names\n",
    "\n",
    "\n",
    "def widen_box(box, percent_x, percent_y):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "        xmin -= w * percent_x\n",
    "        ymin -= h * percent_y\n",
    "        xmax += w * percent_x\n",
    "        ymax += h * percent_y\n",
    "        return (int(xmin), int(ymin), int(xmax), int(ymax))\n",
    "\n",
    "    \n",
    "def draw_json_on_img(img, json_data):\n",
    "    labels = list(set(shape['label'] for shape in json_data['shapes']))\n",
    "    color = {}\n",
    "    for i in range(len(labels)):\n",
    "        color[labels[i]] = (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255))\n",
    "        \n",
    "    img = img.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_size = 0.5\n",
    "    for i, shape in enumerate(json_data['shapes']):\n",
    "        polys = shape['points']\n",
    "        polys = [(int(pt[0]), int(pt[1])) for pt in polys]\n",
    "        label = shape['label']\n",
    "        draw.polygon(polys, outline=color[label], width=2)\n",
    "        # Draw the text on the image\n",
    "        img = np.array(img)\n",
    "        cv2.putText(img, shape['label'], (polys[0][0], polys[0][1]-5), font, font_size, color[label], thickness=1)\n",
    "        img = Image.fromarray(img)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "    return img\n",
    "    \n",
    "    \n",
    "def mask_image(img, boxes, json_data, widen_range_x, widen_range_y):\n",
    "    # widen block\n",
    "    if isinstance(widen_range_x, list) and isinstance(widen_range_y, list):\n",
    "        boxes = [widen_box(box, np.random.uniform(widen_range_x[0], widen_range_x[1]), np.random.uniform(widen_range_y[0], widen_range_y[1])) for box in boxes]\n",
    "    else:\n",
    "        boxes = [widen_box(box, widen_range_x, widen_range_y) for box in boxes]\n",
    "        \n",
    "    \n",
    "    ls_polys2keep = []\n",
    "    ls_area2keep = []\n",
    "    iou_threshold = 0.\n",
    "    for box_idx, box in enumerate(boxes):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        box_pts = [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)]\n",
    "        p_box = Polygon(box_pts)\n",
    "        for shape_idx, shape in enumerate(json_data['shapes']):\n",
    "            if shape_idx in ls_polys2keep:\n",
    "                continue\n",
    "            pts = shape['points']\n",
    "            p_shape = Polygon(pts)\n",
    "            intersect_area = p_box.intersection(p_shape).area\n",
    "            if intersect_area / p_shape.area > iou_threshold:\n",
    "                ls_polys2keep.append(shape_idx)\n",
    "                pts = [coord for pt in pts for coord in pt]\n",
    "                poly_xmin = min(pts[::2])\n",
    "                poly_ymin = min(pts[1::2])\n",
    "                poly_xmax = max(pts[::2])\n",
    "                poly_ymax = max(pts[1::2])\n",
    "                ls_area2keep.append((poly_xmin, poly_ymin, poly_xmax, poly_ymax))\n",
    "\n",
    "    # mask white all area of image that is not in block\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        xmin = max(0, xmin)\n",
    "        ymin = max(0, ymin)\n",
    "        xmax = min(img.shape[1], xmax)\n",
    "        ymax = min(img.shape[0], ymax)\n",
    "        mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "    for area2keep in ls_area2keep:\n",
    "        xmin, ymin, xmax, ymax = area2keep\n",
    "        xmin = int(max(0, xmin))\n",
    "        ymin = int(max(0, ymin))\n",
    "        xmax = int(min(img.shape[1], xmax))\n",
    "        ymax = int(min(img.shape[0], ymax))\n",
    "        mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "    # mask white\n",
    "    img[mask == 0] = 255\n",
    "\n",
    "    # delete all poly that is not in block\n",
    "    ls_idx2del = [idx for idx, shape in enumerate(json_data['shapes']) if idx not in ls_polys2keep]\n",
    "    for idx in sorted(ls_idx2del, reverse=True):\n",
    "        del json_data['shapes'][idx]\n",
    "\n",
    "    return img, json_data\n",
    "        \n",
    "\n",
    "def gen_annotation_for_img(img_fp, xml_fp, json_fp, masked=False, widen_range_x=[0.1, 0.2], widen_range_y=[0.1, 0.25]):\n",
    "    img = Image.open(img_fp).convert(\"RGB\")\n",
    "    boxes, obj_names = parse_xml(xml_fp)\n",
    "    json_data = json.load(open(json_fp))\n",
    "    \n",
    "    if masked:\n",
    "        img, json_data = mask_image(np.array(img), boxes=boxes, json_data=json_data, widen_range_x=widen_range_x, widen_range_y=widen_range_y)\n",
    "        img = Image.fromarray(img)\n",
    "    # pdb.set_trace()\n",
    "        \n",
    "    words, boxes, labels = [], [], []\n",
    "    img_h, img_w = json_data['imageHeight'], json_data['imageWidth']\n",
    "    for i, shape in enumerate(json_data['shapes']):\n",
    "      # words.append(unidecode.unidecode(shape['text'].lower()))\n",
    "      words.append(shape['text'].lower())\n",
    "      labels.append(shape['label'])\n",
    "      pts = [coord for pt in shape['points'] for coord in pt]\n",
    "      xmin = min(pts[0::2])\n",
    "      xmax = max(pts[0::2])\n",
    "      ymin = min(pts[1::2])\n",
    "      ymax = max(pts[1::2])\n",
    "\n",
    "      xmin = max(xmin, 0)\n",
    "      ymin = max(ymin, 0)\n",
    "      xmax = min(img_w, xmax)\n",
    "      ymax = min(img_h, ymax)\n",
    "\n",
    "      boxes.append(normalize_bbox((xmin, ymin, xmax, ymax), img_w, img_h))\n",
    "\n",
    "    return img, words, boxes, labels\n",
    "\n",
    "\n",
    "class CORDDataset(Dataset):\n",
    "    def __init__(self, file_paths, processor=None, max_length=512, masked=False, widen_range_x=[0.1, 0.2], widen_range_y=[0.1, 0.25]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotations (List[List]): List of lists containing the word-level annotations (words, labels, boxes).\n",
    "            image_dir (string): Directory with all the document images.\n",
    "            processor (LayoutLMv2Processor): Processor to prepare the text + image.\n",
    "        \"\"\"\n",
    "        self.ls_img_fp, self.ls_xml_fp, self.ls_json_fp = file_paths\n",
    "        assert len(self.ls_img_fp) == len(self.ls_json_fp) == len(self.ls_xml_fp)\n",
    "        self.processor = processor\n",
    "        self.masked = masked\n",
    "        self.widen_range_x = widen_range_x\n",
    "        self.widen_range_y = widen_range_y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ls_img_fp)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # first, take an image\n",
    "        img_fp = self.ls_img_fp[index]\n",
    "        xml_fp = self.ls_xml_fp[index]\n",
    "        json_fp = self.ls_json_fp[index]\n",
    "        \n",
    "        img, words, boxes, text_labels = gen_annotation_for_img(img_fp, xml_fp, json_fp, masked=self.masked, widen_range_x=self.widen_range_x, widen_range_y=self.widen_range_y)\n",
    "        idx_labels = [label2id[label] for label in text_labels]\n",
    "\n",
    "        encoded_inputs = processor(img, words, boxes=boxes, word_labels=idx_labels, truncation=True, stride =128, \n",
    "                            padding=\"max_length\", max_length=512, return_overflowing_tokens=True, return_offsets_mapping=True, return_tensors=\"pt\")  \n",
    "        \n",
    "        # print(encoded_inputs.keys())\n",
    "        overflow_to_sample_mapping = encoded_inputs.pop('overflow_to_sample_mapping')\n",
    "        offset_mapping = encoded_inputs.pop('offset_mapping')\n",
    "        encoded_inputs.pop('image')\n",
    "        # print('overflow_to_sample_mapping: ', overflow_to_sample_mapping)\n",
    "        # print('offset_mapping: ', offset_mapping)\n",
    "\n",
    "        # remove batch dimension\n",
    "        idx = np.random.randint(0, len(encoded_inputs['image']))\n",
    "        for k, v in encoded_inputs.items():\n",
    "            encoded_inputs[k] = v[idx]\n",
    "      \n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f086fd81-0d5e-4da6-a14a-395a0127e1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(data_dir):\n",
    "    ls_img_fp, ls_xml_fp, ls_json_fp = [], [], []\n",
    "    for img_fp in Path(data_dir).rglob('*.jpg'):\n",
    "        json_fp = img_fp.with_suffix('.json')\n",
    "        xml_fp = img_fp.with_suffix('.xml')\n",
    "        \n",
    "        ls_img_fp.append(str(img_fp))\n",
    "        ls_xml_fp.append(str(xml_fp))\n",
    "        ls_json_fp.append(str(json_fp))\n",
    "    \n",
    "    return ls_img_fp, ls_xml_fp, ls_json_fp\n",
    "\n",
    "\n",
    "train_file_paths = get_file_paths(train_dir)\n",
    "val_file_paths = get_file_paths(val_dir)\n",
    "\n",
    "widen_range_x = [0.1, 0.2]\n",
    "widen_range_y = [0.1, 0.25]\n",
    "train_dataset = CORDDataset(file_paths=train_file_paths, processor=processor, masked=False, \n",
    "                            widen_range_x=widen_range_x, widen_range_y=widen_range_y)\n",
    "val_dataset = CORDDataset(file_paths=val_file_paths, processor=processor, masked=False, \n",
    "                          widen_range_x=0.1, widen_range_y=0.15)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "577f6b1b-2981-4b24-b0c6-13c2774511c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29822/1715182305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_29822/2756375183.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# remove batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "encoding = val_dataset[9]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dc669d9-30e8-4c77-bdd7-e7a977aee2a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "(',', 'text', tensor([244, 519, 314, 539]))\n",
      "('187', 'text', tensor([244, 519, 314, 539]))\n",
      "(',', 'text', tensor([244, 519, 314, 539]))\n",
      "('344', 'text', tensor([244, 519, 314, 539]))\n",
      "(',', 'text', tensor([244, 519, 314, 539]))\n",
      "('649', 'text', tensor([244, 519, 314, 539]))\n",
      "('58', 'text', tensor([335, 516, 398, 537]))\n",
      "(',', 'text', tensor([335, 516, 398, 537]))\n",
      "('25', 'text', tensor([335, 516, 398, 537]))\n",
      "('2', 'text', tensor([335, 516, 398, 537]))\n",
      "(',', 'text', tensor([335, 516, 398, 537]))\n",
      "('41', 'text', tensor([335, 516, 398, 537]))\n",
      "('9,5', 'text', tensor([335, 516, 398, 537]))\n",
      "('07', 'text', tensor([335, 516, 398, 537]))\n",
      "('58', 'text', tensor([418, 517, 479, 534]))\n",
      "(',', 'text', tensor([418, 517, 479, 534]))\n",
      "('25', 'text', tensor([418, 517, 479, 534]))\n",
      "('2', 'text', tensor([418, 517, 479, 534]))\n",
      "(',', 'text', tensor([418, 517, 479, 534]))\n",
      "('41', 'text', tensor([418, 517, 479, 534]))\n",
      "('9,5', 'text', tensor([418, 517, 479, 534]))\n",
      "('07', 'text', tensor([418, 517, 479, 534]))\n",
      "('supplement', 'text', tensor([120, 507, 182, 527]))\n",
      "('ary', 'text', tensor([120, 507, 182, 527]))\n",
      "('', 'text', tensor([762, 506, 830, 526]))\n",
      "('577', 'text', tensor([762, 506, 830, 526]))\n",
      "(',', 'text', tensor([762, 506, 830, 526]))\n",
      "('439', 'text', tensor([762, 506, 830, 526]))\n",
      "(',', 'text', tensor([762, 506, 830, 526]))\n",
      "('764', 'text', tensor([762, 506, 830, 526]))\n",
      "(',', 'text', tensor([762, 506, 830, 526]))\n",
      "('156', 'text', tensor([762, 506, 830, 526]))\n",
      "('58', 'text', tensor([859, 503, 925, 523]))\n",
      "(',', 'text', tensor([859, 503, 925, 523]))\n",
      "('25', 'text', tensor([859, 503, 925, 523]))\n",
      "('2', 'text', tensor([859, 503, 925, 523]))\n",
      "(',', 'text', tensor([859, 503, 925, 523]))\n",
      "('41', 'text', tensor([859, 503, 925, 523]))\n",
      "('9,5', 'text', tensor([859, 503, 925, 523]))\n",
      "('07', 'text', tensor([859, 503, 925, 523]))\n",
      "('charter', 'text', tensor([120, 493, 151, 510]))\n",
      "('2.', 'text', tensor([104, 494, 114, 510]))\n",
      "('capital', 'text', tensor([153, 491, 182, 510]))\n",
      "('tre', 'text', tensor([121, 479, 158, 494]))\n",
      "('as', 'text', tensor([121, 479, 158, 494]))\n",
      "('ury', 'text', tensor([121, 479, 158, 494]))\n",
      "('share', 'text', tensor([159, 477, 184, 494]))\n",
      "('1.4', 'text', tensor([104, 477, 121, 496]))\n",
      "('.', 'text', tensor([104, 477, 121, 496]))\n",
      "('(21', 'text', tensor([330, 472, 398, 489]))\n",
      "('.', 'text', tensor([330, 472, 398, 489]))\n",
      "('98', 'text', tensor([330, 472, 398, 489]))\n",
      "('3.9', 'text', tensor([330, 472, 398, 489]))\n",
      "('12', 'text', tensor([330, 472, 398, 489]))\n",
      "('.', 'text', tensor([330, 472, 398, 489]))\n",
      "('738', 'text', tensor([330, 472, 398, 489]))\n",
      "(')', 'text', tensor([330, 472, 398, 489]))\n",
      "('(', 'text', tensor([243, 471, 314, 495]))\n",
      "('34', 'text', tensor([243, 471, 314, 495]))\n",
      "('.', 'text', tensor([243, 471, 314, 495]))\n",
      "('661', 'text', tensor([243, 471, 314, 495]))\n",
      "('.', 'text', tensor([243, 471, 314, 495]))\n",
      "('96', 'text', tensor([243, 471, 314, 495]))\n",
      "('2.', 'text', tensor([243, 471, 314, 495]))\n",
      "('785', 'text', tensor([243, 471, 314, 495]))\n",
      "(')', 'text', tensor([243, 471, 314, 495]))\n",
      "('(', 'text', tensor([422, 468, 480, 489]))\n",
      "('459', 'text', tensor([422, 468, 480, 489]))\n",
      "('.', 'text', tensor([422, 468, 480, 489]))\n",
      "('4', 'text', tensor([422, 468, 480, 489]))\n",
      "('47', 'text', tensor([422, 468, 480, 489]))\n",
      "('.', 'text', tensor([422, 468, 480, 489]))\n",
      "('500', 'text', tensor([422, 468, 480, 489]))\n",
      "(')', 'text', tensor([422, 468, 480, 489]))\n",
      "('13.', 'text', tensor([503, 463, 571, 489]))\n",
      "('82', 'text', tensor([503, 463, 571, 489]))\n",
      "('7.8', 'text', tensor([503, 463, 571, 489]))\n",
      "('09.', 'text', tensor([503, 463, 571, 489]))\n",
      "('09', 'text', tensor([503, 463, 571, 489]))\n",
      "('7', 'text', tensor([503, 463, 571, 489]))\n",
      "('(1', 'text', tensor([583, 465, 650, 483]))\n",
      "('.', 'text', tensor([583, 465, 650, 483]))\n",
      "('33', 'text', tensor([583, 465, 650, 483]))\n",
      "('0.7', 'text', tensor([583, 465, 650, 483]))\n",
      "('10', 'text', tensor([583, 465, 650, 483]))\n",
      "('.', 'text', tensor([583, 465, 650, 483]))\n",
      "('900', 'text', tensor([583, 465, 650, 483]))\n",
      "(')', 'text', tensor([583, 465, 650, 483]))\n",
      "('component', 'text', tensor([119, 462, 167, 482]))\n",
      "('(21', 'text', tensor([762, 460, 830, 481]))\n",
      "(',', 'text', tensor([762, 460, 830, 481]))\n",
      "('29', 'text', tensor([762, 460, 830, 481]))\n",
      "('3', 'text', tensor([762, 460, 830, 481]))\n",
      "(',', 'text', tensor([762, 460, 830, 481]))\n",
      "('601', 'text', tensor([762, 460, 830, 481]))\n",
      "(',', 'text', tensor([762, 460, 830, 481]))\n",
      "('188', 'text', tensor([762, 460, 830, 481]))\n",
      "(')', 'text', tensor([762, 460, 830, 481]))\n",
      "('4', 'text', tensor([680, 460, 744, 483]))\n",
      "(',', 'text', tensor([680, 460, 744, 483]))\n",
      "('2', 'text', tensor([680, 460, 744, 483]))\n",
      "('36', 'text', tensor([680, 460, 744, 483]))\n",
      "(',', 'text', tensor([680, 460, 744, 483]))\n",
      "('13', 'text', tensor([680, 460, 744, 483]))\n",
      "('5,7', 'text', tensor([680, 460, 744, 483]))\n",
      "('29', 'text', tensor([680, 460, 744, 483]))\n",
      "('(19', 'text', tensor([853, 458, 925, 478]))\n",
      "(',', 'text', tensor([853, 458, 925, 478]))\n",
      "('07', 'text', tensor([853, 458, 925, 478]))\n",
      "('8', 'text', tensor([853, 458, 925, 478]))\n",
      "(',', 'text', tensor([853, 458, 925, 478]))\n",
      "('48', 'text', tensor([853, 458, 925, 478]))\n",
      "('7,9', 'text', tensor([853, 458, 925, 478]))\n",
      "('09)', 'text', tensor([853, 458, 925, 478]))\n",
      "('113', 'text', tensor([243, 457, 314, 477]))\n",
      "(',', 'text', tensor([243, 457, 314, 477]))\n",
      "('779', 'text', tensor([243, 457, 314, 477]))\n",
      "(',', 'text', tensor([243, 457, 314, 477]))\n",
      "('09', 'text', tensor([243, 457, 314, 477]))\n",
      "('5,7', 'text', tensor([243, 457, 314, 477]))\n",
      "('85', 'text', tensor([243, 457, 314, 477]))\n",
      "('(', 'text', tensor([492, 449, 549, 472]))\n",
      "('113', 'text', tensor([492, 449, 549, 472]))\n",
      "('.', 'text', tensor([492, 449, 549, 472]))\n",
      "('779', 'text', tensor([492, 449, 549, 472]))\n",
      "('.', 'text', tensor([492, 449, 549, 472]))\n",
      "('09', 'text', tensor([492, 449, 549, 472]))\n",
      "('5', 'text', tensor([492, 449, 549, 472]))\n",
      "(':', 'text', tensor([546, 448, 569, 471]))\n",
      "('785', 'text', tensor([546, 448, 569, 471]))\n",
      "(')', 'text', tensor([546, 448, 569, 471]))\n",
      "('equi', 'text', tensor([155, 448, 184, 465]))\n",
      "('ty', 'text', tensor([155, 448, 184, 465]))\n",
      "('bond', 'text', tensor([119, 448, 155, 466]))\n",
      "('s', 'text', tensor([119, 448, 155, 466]))\n",
      "('-', 'text', tensor([119, 448, 155, 466]))\n",
      "('25', 'phone', tensor([383, 387, 428, 408]))\n",
      "('(', 'phone', tensor([383, 387, 428, 408]))\n",
      "('8', 'phone', tensor([383, 387, 428, 408]))\n",
      "('75)', 'phone', tensor([383, 387, 428, 408]))\n",
      "('08', 'phone', tensor([383, 387, 428, 408]))\n",
      "('mob', 'marker_phone', tensor([341, 386, 368, 410]))\n",
      "(':', 'text', tensor([373, 388, 381, 410]))\n",
      "('representativ', 'marker_represented_name', tensor([343, 362, 409, 379]))\n",
      "('e', 'marker_represented_name', tensor([343, 362, 409, 379]))\n",
      "(':', 'marker_represented_name', tensor([343, 362, 409, 379]))\n",
      "('je', 'represented_name', tensor([410, 357, 436, 380]))\n",
      "('ff', 'represented_name', tensor([410, 357, 436, 380]))\n",
      "('beat', 'represented_name', tensor([436, 356, 570, 378]))\n",
      "('tie', 'represented_name', tensor([436, 356, 570, 378]))\n",
      "('-', 'represented_name', tensor([436, 356, 570, 378]))\n",
      "('data', 'represented_name', tensor([436, 356, 570, 378]))\n",
      "('.', 'represented_name', tensor([436, 356, 570, 378]))\n",
      "('assist', 'represented_name', tensor([436, 356, 570, 378]))\n",
      "('ant', 'represented_name', tensor([436, 356, 570, 378]))\n",
      "('code', 'marker_tax', tensor([370, 339, 394, 357]))\n",
      "('tax', 'marker_tax', tensor([339, 339, 360, 357]))\n",
      "('05', 'tax', tensor([410, 337, 463, 354]))\n",
      "('94', 'tax', tensor([410, 337, 463, 354]))\n",
      "('190', 'tax', tensor([410, 337, 463, 354]))\n",
      "('45', 'tax', tensor([410, 337, 463, 354]))\n",
      "('5', 'tax', tensor([410, 337, 463, 354]))\n",
      "('add', 'marker_company_address', tensor([339, 311, 367, 335]))\n",
      "('rad', 'company_address', tensor([382, 310, 483, 333]))\n",
      "('cliff', 'company_address', tensor([382, 310, 483, 333]))\n",
      "('a', 'company_address', tensor([382, 310, 483, 333]))\n",
      "('venue', 'company_address', tensor([382, 310, 483, 333]))\n",
      "('', 'company_address', tensor([365, 313, 380, 333]))\n",
      "(':0', 'company_address', tensor([365, 313, 380, 333]))\n",
      "('lot', 'company_address', tensor([481, 309, 510, 330]))\n",
      "('17', 'company_address', tensor([508, 309, 604, 327]))\n",
      "('r', 'company_address', tensor([508, 309, 604, 327]))\n",
      "('ny', 'company_address', tensor([508, 309, 604, 327]))\n",
      "('c', 'company_address', tensor([508, 309, 604, 327]))\n",
      "('.', 'company_address', tensor([508, 309, 604, 327]))\n",
      "('ny', 'company_address', tensor([508, 309, 604, 327]))\n",
      "('10', 'company_address', tensor([508, 309, 604, 327]))\n",
      "('469', 'company_address', tensor([508, 309, 604, 327]))\n",
      "('dai', 'company_name', tensor([339, 288, 361, 307]))\n",
      "('tien', 'company_name', tensor([399, 285, 428, 307]))\n",
      "('nam', 'company_name', tensor([361, 285, 390, 309]))\n",
      "('servi', 'company_name', tensor([428, 285, 498, 304]))\n",
      "('co', 'company_name', tensor([428, 285, 498, 304]))\n",
      "('.', 'company_name', tensor([428, 285, 498, 304]))\n",
      "(',', 'company_name', tensor([428, 285, 498, 304]))\n",
      "('lt', 'company_name', tensor([428, 285, 498, 304]))\n",
      "('d', 'company_name', tensor([428, 285, 498, 304]))\n",
      "('presente', 'marker_represented_name', tensor([336, 229, 383, 250]))\n",
      "('d', 'marker_represented_name', tensor([336, 229, 383, 250]))\n",
      "('alma', 'represented_name', tensor([427, 229, 453, 246]))\n",
      "('miss', 'represented_name', tensor([402, 229, 425, 247]))\n",
      "('by', 'marker_represented_name', tensor([384, 229, 402, 249]))\n",
      "(':', 'marker_represented_name', tensor([384, 229, 402, 249]))\n",
      "('limon', 'represented_name', tensor([453, 226, 496, 247]))\n",
      "('es', 'represented_name', tensor([453, 226, 496, 247]))\n",
      "('director', 'represented_name', tensor([548, 225, 589, 243]))\n",
      "('vụ', 'represented_name', tensor([527, 225, 548, 244]))\n",
      "(':', 'represented_name', tensor([527, 225, 548, 244]))\n",
      "('chức', 'represented_name', tensor([498, 224, 528, 246]))\n",
      "(':', 'text', tensor([373, 208, 381, 225]))\n",
      "('tel', 'marker_phone', tensor([355, 206, 374, 227]))\n",
      "('city', 'marker_phone', tensor([334, 206, 358, 229]))\n",
      "('+', 'phone', tensor([389, 205, 439, 225]))\n",
      "('9', 'phone', tensor([389, 205, 439, 225]))\n",
      "('08.', 'phone', tensor([389, 205, 439, 225]))\n",
      "('34', 'phone', tensor([389, 205, 439, 225]))\n",
      "('.', 'phone', tensor([389, 205, 439, 225]))\n",
      "('92', 'phone', tensor([389, 205, 439, 225]))\n",
      "(':', 'tax', tensor([355, 180, 415, 197]))\n",
      "('494', 'tax', tensor([355, 180, 415, 197]))\n",
      "('450', 'tax', tensor([355, 180, 415, 197]))\n",
      "('66', 'tax', tensor([355, 180, 415, 197]))\n",
      "('31', 'tax', tensor([355, 180, 415, 197]))\n",
      "(':', 'text', tensor([488, 180, 497, 196]))\n",
      "('tax', 'marker_tax', tensor([333, 178, 355, 203]))\n",
      "('+2', 'fax', tensor([504, 176, 557, 196]))\n",
      "('(', 'fax', tensor([504, 176, 557, 196]))\n",
      "('15', 'fax', tensor([504, 176, 557, 196]))\n",
      "('47)', 'fax', tensor([504, 176, 557, 196]))\n",
      "('17', 'fax', tensor([504, 176, 557, 196]))\n",
      "('x', 'marker_fax', tensor([462, 176, 487, 199]))\n",
      "('no', 'marker_fax', tensor([462, 176, 487, 199]))\n",
      "('fax', 'marker_fax', tensor([441, 176, 469, 199]))\n",
      "('address', 'marker_company_address', tensor([337, 156, 386, 177]))\n",
      "('conta', 'company_address', tensor([456, 155, 505, 172]))\n",
      "('gem', 'company_address', tensor([456, 155, 505, 172]))\n",
      "('pala', 'company_address', tensor([419, 155, 442, 174]))\n",
      "(':', 'text', tensor([388, 157, 397, 176]))\n",
      "('32', 'company_address', tensor([524, 154, 570, 171]))\n",
      "('113', 'company_address', tensor([524, 154, 570, 171]))\n",
      "('-100', 'company_address', tensor([524, 154, 570, 171]))\n",
      "('mg', 'company_address', tensor([504, 154, 524, 172]))\n",
      "('32', 'company_address', tensor([441, 154, 457, 174]))\n",
      "('buy', 'marker_company_name', tensor([359, 137, 397, 154]))\n",
      "('er', 'marker_company_name', tensor([359, 137, 397, 154]))\n",
      "(':', 'company_name', tensor([399, 135, 435, 152]))\n",
      "('hung', 'company_name', tensor([399, 135, 435, 152]))\n",
      "('the', 'marker_company_name', tensor([333, 133, 359, 157]))\n",
      "('phu', 'company_name', tensor([445, 133, 492, 150]))\n",
      "('ong', 'company_name', tensor([445, 133, 492, 150]))\n",
      "('co', 'company_name', tensor([491, 131, 536, 151]))\n",
      "('.', 'company_name', tensor([491, 131, 536, 151]))\n",
      "(',', 'company_name', tensor([491, 131, 536, 151]))\n",
      "('lt', 'company_name', tensor([491, 131, 536, 151]))\n",
      "('d', 'company_name', tensor([491, 131, 536, 151]))\n",
      "('.', 'company_name', tensor([491, 131, 536, 151]))\n",
      "('separate', 'text', tensor([145, 116, 207, 140]))\n",
      "('inter', 'text', tensor([ 94, 114, 143, 141]))\n",
      "('im', 'text', tensor([ 94, 114, 143, 141]))\n",
      "('statement', 'text', tensor([210, 114, 280, 138]))\n",
      "('changes', 'text', tensor([304, 114, 363, 134]))\n",
      "('of', 'text', tensor([283, 114, 302, 137]))\n",
      "('owners', 'text', tensor([381, 113, 435, 131]))\n",
      "(\"'\", 'text', tensor([381, 113, 435, 131]))\n",
      "('equi', 'text', tensor([438, 112, 484, 129]))\n",
      "('ty', 'text', tensor([438, 112, 484, 129]))\n",
      "('in', 'text', tensor([362, 112, 379, 133]))\n",
      "('corporation', 'text', tensor([201,  74, 286,  97]))\n",
      "('securi', 'text', tensor([125,  72, 196, 103]))\n",
      "('ties', 'text', tensor([125,  72, 196, 103]))\n",
      "('s', 'text', tensor([ 93,  73, 122, 105]))\n",
      "('si', 'text', tensor([ 93,  73, 122, 105]))\n",
      "('b', 'text', tensor([836,  60, 900,  82]))\n",
      "('04', 'text', tensor([836,  60, 900,  82]))\n",
      "('a', 'text', tensor([836,  60, 900,  82]))\n",
      "('-', 'text', tensor([836,  60, 900,  82]))\n",
      "('ct', 'text', tensor([836,  60, 900,  82]))\n",
      "('ck', 'text', tensor([836,  60, 900,  82]))\n",
      "('</s>', 'SPECIAL', tensor([1000, 1000, 1000, 1000]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n",
      "('<pad>', 'SPECIAL', tensor([0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "ls_token = [processor.tokenizer.decode(input_id) for input_id in encoding['input_ids']]\n",
    "ls_label = [id2label[int(label_id)] if label_id != -100 else 'SPECIAL' for label_id in encoding['labels'] ]\n",
    "ls_bb = list(encoding['bbox'])\n",
    "for item in zip(ls_token, ls_label, ls_bb):\n",
    "  print(item)\n",
    "  # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "892721ca-6813-44c3-825f-63bb6b7105a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([6, 512])\n",
      "attention_mask torch.Size([6, 512])\n",
      "bbox torch.Size([6, 512, 4])\n",
      "labels torch.Size([6, 512])\n",
      "image torch.Size([6, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=6, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "for item in train_dataloader:\n",
    "  for k, v in item.items():\n",
    "    print(k, v.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fbc27-8f78-4ffc-8eba-4b6682de8f24",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4473d92-f536-487e-9ec7-6884ee8a5001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LiltForTokenClassification were not initialized from the model checkpoint at SCUT-DLVCLab/lilt-infoxlm-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LiltForTokenClassification\n",
    "\n",
    "model = LiltForTokenClassification.from_pretrained('SCUT-DLVCLab/lilt-infoxlm-base', id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e97bd98-c0fc-4e06-bb14-1416e07b75fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LiltForTokenClassification(\n",
       "  (lilt): LiltModel(\n",
       "    (embeddings): LiltTextEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layout_embeddings): LiltLayoutEmbeddings(\n",
       "      (x_position_embeddings): Embedding(1024, 128)\n",
       "      (y_position_embeddings): Embedding(1024, 128)\n",
       "      (h_position_embeddings): Embedding(1024, 128)\n",
       "      (w_position_embeddings): Embedding(1024, 128)\n",
       "      (box_position_embeddings): Embedding(514, 192, padding_idx=1)\n",
       "      (box_linear_embeddings): Linear(in_features=768, out_features=192, bias=True)\n",
       "      (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LiltEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): LiltLayer(\n",
       "          (attention): LiltAttention(\n",
       "            (self): LiltSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (layout_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (layout_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layout_output): LiltSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LiltOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (layout_intermediate): LiltIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (layout_output): LiltOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (LayerNorm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b09c3-6b46-40d2-9f6f-8dacb10125b6",
   "metadata": {},
   "source": [
    "# Hugging Face Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8d51543-f98b-4124-bfc4-252177e4e0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tax',\n",
       " 'marker_phone',\n",
       " 'marker_company_address',\n",
       " 'company_name',\n",
       " 'bank_name',\n",
       " 'marker_company_name',\n",
       " 'company_address',\n",
       " 'marker_account_number',\n",
       " 'marker_bank_address',\n",
       " 'marker_tax',\n",
       " 'marker_swift_code',\n",
       " 'fax',\n",
       " 'bank_address',\n",
       " 'account_number',\n",
       " 'text',\n",
       " 'marker_represented_name',\n",
       " 'swift_code',\n",
       " 'marker_fax',\n",
       " 'represented_name',\n",
       " 'marker_bank_name',\n",
       " 'phone']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fae0c846-a42b-42cb-9a45-0602ae9a1714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "return_entity_level_metrics = False\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b3c14e8-12f4-45f7-83fa-9fcb3f40f876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"ckpt/nonmasked/fake_data/lilt\",\n",
    "                                  num_train_epochs=100,\n",
    "                                  learning_rate=5e-5,\n",
    "                                  evaluation_strategy=\"steps\",\n",
    "                                  save_strategy='steps',\n",
    "                                  eval_steps=500,\n",
    "                                  save_steps=500,\n",
    "                                  save_total_limit=15,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1\",\n",
    "                                  warmup_ratio = 0.1,\n",
    "                                  do_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e7a2f97-31a3-4c86-a6ab-59f85a603a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers.data.data_collator import default_data_collator\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "  def get_train_dataloader(self):\n",
    "    return train_dataloader\n",
    "\n",
    "  def get_eval_dataloader(self, eval_dataset = None):\n",
    "    return val_dataloader\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25127d4b-851c-4ec6-8c89-9784479cdc39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29822/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1638\u001b[0m         )\n\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                 if (\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2644\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2645\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2678\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/tungtx2/env_ocr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'image'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
